{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Tic Tac Toe\n",
    "\n",
    "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
    "\n",
    "![Tic Tac Toe Grids](tttboard.jpg)\n",
    "\n",
    "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
    "\n",
    "## Step 1: Data Engineering\n",
    "\n",
    "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
    "\n",
    "1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "1. Convert the categorical values to numeric in all columns.\n",
    "1. Separate the inputs and output.\n",
    "1. Normalize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TL TM TR ML MM MR BL BM BR  class\n",
      "0  x  x  x  x  o  o  x  o  o   True\n",
      "1  x  x  x  x  o  o  o  x  o   True\n",
      "2  x  x  x  x  o  o  o  o  x   True\n",
      "3  x  x  x  x  o  o  o  b  b   True\n",
      "4  x  x  x  x  o  o  b  o  b   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\torre\\Desktop\\lab-neural-networks-master\\your-code\\tic-tac-toe.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Convert categorical values ('x', 'o', 'b') to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.columns[:-1]:  # Exclude target column\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Encode target column (True/False) -> (1/0)\n",
    "df['class'] = df['class'].astype(int)\n",
    "\n",
    "# Split dataset into features (X) and target (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Neural Network\n",
    "\n",
    "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
    "\n",
    "1. Split the training and test data.\n",
    "1. Create a `Sequential` model.\n",
    "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
    "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "1. Fit the training data.\n",
    "1. Evaluate your neural network model with the test data.\n",
    "1. Save your model as `tic-tac-toe.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\torre\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6598 - loss: 0.6329 - val_accuracy: 0.7396 - val_loss: 0.5668\n",
      "Epoch 2/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7431 - loss: 0.5284 - val_accuracy: 0.7708 - val_loss: 0.5197\n",
      "Epoch 3/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4380 - val_accuracy: 0.7969 - val_loss: 0.4927\n",
      "Epoch 4/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.3994 - val_accuracy: 0.8177 - val_loss: 0.4137\n",
      "Epoch 5/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8682 - loss: 0.3025 - val_accuracy: 0.7969 - val_loss: 0.4434\n",
      "Epoch 6/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8936 - loss: 0.2657 - val_accuracy: 0.8385 - val_loss: 0.3966\n",
      "Epoch 7/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.2473 - val_accuracy: 0.8542 - val_loss: 0.3513\n",
      "Epoch 8/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.2422 - val_accuracy: 0.8385 - val_loss: 0.4435\n",
      "Epoch 9/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.1962 - val_accuracy: 0.8333 - val_loss: 0.3625\n",
      "Epoch 10/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.2624 - val_accuracy: 0.8281 - val_loss: 0.4242\n",
      "Epoch 11/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9332 - loss: 0.1599 - val_accuracy: 0.9010 - val_loss: 0.2344\n",
      "Epoch 12/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.1112 - val_accuracy: 0.8750 - val_loss: 0.3260\n",
      "Epoch 13/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1091 - val_accuracy: 0.8542 - val_loss: 0.4617\n",
      "Epoch 14/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1541 - val_accuracy: 0.9167 - val_loss: 0.2085\n",
      "Epoch 15/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0770 - val_accuracy: 0.9219 - val_loss: 0.1629\n",
      "Epoch 16/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0566 - val_accuracy: 0.9479 - val_loss: 0.1478\n",
      "Epoch 17/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9587 - loss: 0.0942 - val_accuracy: 0.9115 - val_loss: 0.2136\n",
      "Epoch 18/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1054 - val_accuracy: 0.9531 - val_loss: 0.1321\n",
      "Epoch 19/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0364 - val_accuracy: 0.9323 - val_loss: 0.1792\n",
      "Epoch 20/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0292 - val_accuracy: 0.9479 - val_loss: 0.1342\n",
      "Epoch 21/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9951 - loss: 0.0146 - val_accuracy: 0.9479 - val_loss: 0.1301\n",
      "Epoch 22/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9583 - val_loss: 0.1525\n",
      "Epoch 23/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9583 - val_loss: 0.1396\n",
      "Epoch 24/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9583 - val_loss: 0.1406\n",
      "Epoch 25/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9583 - val_loss: 0.1402\n",
      "Epoch 26/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.9711e-04 - val_accuracy: 0.9583 - val_loss: 0.1418\n",
      "Epoch 27/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.5880e-04 - val_accuracy: 0.9583 - val_loss: 0.1413\n",
      "Epoch 28/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0390e-04 - val_accuracy: 0.9531 - val_loss: 0.1427\n",
      "Epoch 29/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8478e-04 - val_accuracy: 0.9531 - val_loss: 0.1432\n",
      "Epoch 30/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0617e-04 - val_accuracy: 0.9531 - val_loss: 0.1429\n",
      "Epoch 31/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0284e-04 - val_accuracy: 0.9531 - val_loss: 0.1424\n",
      "Epoch 32/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2973e-04 - val_accuracy: 0.9531 - val_loss: 0.1440\n",
      "Epoch 33/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9670e-04 - val_accuracy: 0.9531 - val_loss: 0.1431\n",
      "Epoch 34/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2848e-04 - val_accuracy: 0.9635 - val_loss: 0.1452\n",
      "Epoch 35/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9567e-04 - val_accuracy: 0.9635 - val_loss: 0.1435\n",
      "Epoch 36/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3008e-04 - val_accuracy: 0.9635 - val_loss: 0.1459\n",
      "Epoch 37/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3959e-04 - val_accuracy: 0.9635 - val_loss: 0.1443\n",
      "Epoch 38/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7604e-04 - val_accuracy: 0.9635 - val_loss: 0.1427\n",
      "Epoch 39/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.3427e-04 - val_accuracy: 0.9635 - val_loss: 0.1442\n",
      "Epoch 40/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0917e-04 - val_accuracy: 0.9635 - val_loss: 0.1432\n",
      "Epoch 41/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8513e-04 - val_accuracy: 0.9635 - val_loss: 0.1425\n",
      "Epoch 42/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8999e-04 - val_accuracy: 0.9635 - val_loss: 0.1448\n",
      "Epoch 43/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7231e-04 - val_accuracy: 0.9635 - val_loss: 0.1440\n",
      "Epoch 44/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4962e-04 - val_accuracy: 0.9635 - val_loss: 0.1440\n",
      "Epoch 45/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.4541e-04 - val_accuracy: 0.9635 - val_loss: 0.1449\n",
      "Epoch 46/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4261e-04 - val_accuracy: 0.9635 - val_loss: 0.1449\n",
      "Epoch 47/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3051e-04 - val_accuracy: 0.9635 - val_loss: 0.1443\n",
      "Epoch 48/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.1561e-04 - val_accuracy: 0.9635 - val_loss: 0.1453\n",
      "Epoch 49/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3620e-04 - val_accuracy: 0.9635 - val_loss: 0.1455\n",
      "Epoch 50/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.0398e-04 - val_accuracy: 0.9635 - val_loss: 0.1460\n",
      "Epoch 51/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.0343e-04 - val_accuracy: 0.9635 - val_loss: 0.1464\n",
      "Epoch 52/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.8625e-05 - val_accuracy: 0.9635 - val_loss: 0.1449\n",
      "Epoch 53/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.6839e-05 - val_accuracy: 0.9635 - val_loss: 0.1451\n",
      "Epoch 54/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.4672e-05 - val_accuracy: 0.9635 - val_loss: 0.1463\n",
      "Epoch 55/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.5203e-05 - val_accuracy: 0.9635 - val_loss: 0.1450\n",
      "Epoch 56/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.1609e-05 - val_accuracy: 0.9635 - val_loss: 0.1465\n",
      "Epoch 57/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.6524e-05 - val_accuracy: 0.9635 - val_loss: 0.1466\n",
      "Epoch 58/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.9438e-05 - val_accuracy: 0.9635 - val_loss: 0.1466\n",
      "Epoch 59/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.5466e-05 - val_accuracy: 0.9635 - val_loss: 0.1476\n",
      "Epoch 60/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5555e-05 - val_accuracy: 0.9635 - val_loss: 0.1478\n",
      "Epoch 61/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.9533e-05 - val_accuracy: 0.9635 - val_loss: 0.1473\n",
      "Epoch 62/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.6012e-05 - val_accuracy: 0.9583 - val_loss: 0.1472\n",
      "Epoch 63/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.6436e-05 - val_accuracy: 0.9583 - val_loss: 0.1486\n",
      "Epoch 64/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7846e-05 - val_accuracy: 0.9635 - val_loss: 0.1467\n",
      "Epoch 65/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6285e-05 - val_accuracy: 0.9583 - val_loss: 0.1478\n",
      "Epoch 66/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0076e-05 - val_accuracy: 0.9583 - val_loss: 0.1489\n",
      "Epoch 67/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.2524e-05 - val_accuracy: 0.9583 - val_loss: 0.1479\n",
      "Epoch 68/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9553e-05 - val_accuracy: 0.9583 - val_loss: 0.1488\n",
      "Epoch 69/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1538e-05 - val_accuracy: 0.9583 - val_loss: 0.1482\n",
      "Epoch 70/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6219e-05 - val_accuracy: 0.9583 - val_loss: 0.1496\n",
      "Epoch 71/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.8397e-05 - val_accuracy: 0.9583 - val_loss: 0.1492\n",
      "Epoch 72/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1147e-05 - val_accuracy: 0.9583 - val_loss: 0.1492\n",
      "Epoch 73/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.4588e-05 - val_accuracy: 0.9583 - val_loss: 0.1501\n",
      "Epoch 74/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6246e-05 - val_accuracy: 0.9583 - val_loss: 0.1501\n",
      "Epoch 75/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3737e-05 - val_accuracy: 0.9583 - val_loss: 0.1503\n",
      "Epoch 76/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2590e-05 - val_accuracy: 0.9583 - val_loss: 0.1500\n",
      "Epoch 77/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3472e-05 - val_accuracy: 0.9583 - val_loss: 0.1505\n",
      "Epoch 78/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7119e-05 - val_accuracy: 0.9583 - val_loss: 0.1509\n",
      "Epoch 79/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.0386e-05 - val_accuracy: 0.9583 - val_loss: 0.1506\n",
      "Epoch 80/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8214e-05 - val_accuracy: 0.9583 - val_loss: 0.1507\n",
      "Epoch 81/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2113e-05 - val_accuracy: 0.9583 - val_loss: 0.1506\n",
      "Epoch 82/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8555e-05 - val_accuracy: 0.9583 - val_loss: 0.1511\n",
      "Epoch 83/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0893e-05 - val_accuracy: 0.9583 - val_loss: 0.1521\n",
      "Epoch 84/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.3532e-05 - val_accuracy: 0.9583 - val_loss: 0.1527\n",
      "Epoch 85/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7812e-05 - val_accuracy: 0.9583 - val_loss: 0.1527\n",
      "Epoch 86/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7929e-05 - val_accuracy: 0.9583 - val_loss: 0.1518\n",
      "Epoch 87/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5495e-05 - val_accuracy: 0.9531 - val_loss: 0.1523\n",
      "Epoch 88/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1088e-05 - val_accuracy: 0.9531 - val_loss: 0.1531\n",
      "Epoch 89/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.4783e-05 - val_accuracy: 0.9531 - val_loss: 0.1530\n",
      "Epoch 90/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.1136e-05 - val_accuracy: 0.9531 - val_loss: 0.1541\n",
      "Epoch 91/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0264e-05 - val_accuracy: 0.9531 - val_loss: 0.1541\n",
      "Epoch 92/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.8805e-05 - val_accuracy: 0.9531 - val_loss: 0.1530\n",
      "Epoch 93/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.8766e-05 - val_accuracy: 0.9531 - val_loss: 0.1543\n",
      "Epoch 94/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6577e-05 - val_accuracy: 0.9531 - val_loss: 0.1545\n",
      "Epoch 95/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.5893e-05 - val_accuracy: 0.9531 - val_loss: 0.1541\n",
      "Epoch 96/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.7198e-05 - val_accuracy: 0.9531 - val_loss: 0.1555\n",
      "Epoch 97/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.7435e-05 - val_accuracy: 0.9531 - val_loss: 0.1556\n",
      "Epoch 98/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.5687e-05 - val_accuracy: 0.9531 - val_loss: 0.1557\n",
      "Epoch 99/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5847e-05 - val_accuracy: 0.9531 - val_loss: 0.1561\n",
      "Epoch 100/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5334e-05 - val_accuracy: 0.9531 - val_loss: 0.1568\n",
      "Epoch 101/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5403e-05 - val_accuracy: 0.9531 - val_loss: 0.1563\n",
      "Epoch 102/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2559e-05 - val_accuracy: 0.9531 - val_loss: 0.1563\n",
      "Epoch 103/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2948e-05 - val_accuracy: 0.9531 - val_loss: 0.1578\n",
      "Epoch 104/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2128e-05 - val_accuracy: 0.9531 - val_loss: 0.1579\n",
      "Epoch 105/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2643e-05 - val_accuracy: 0.9531 - val_loss: 0.1586\n",
      "Epoch 106/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2455e-05 - val_accuracy: 0.9531 - val_loss: 0.1579\n",
      "Epoch 107/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2245e-05 - val_accuracy: 0.9531 - val_loss: 0.1592\n",
      "Epoch 108/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1214e-05 - val_accuracy: 0.9531 - val_loss: 0.1588\n",
      "Epoch 109/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0955e-05 - val_accuracy: 0.9479 - val_loss: 0.1591\n",
      "Epoch 110/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0028e-05 - val_accuracy: 0.9479 - val_loss: 0.1599\n",
      "Epoch 111/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1089e-05 - val_accuracy: 0.9479 - val_loss: 0.1591\n",
      "Epoch 112/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6031e-06 - val_accuracy: 0.9479 - val_loss: 0.1599\n",
      "Epoch 113/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2946e-06 - val_accuracy: 0.9479 - val_loss: 0.1608\n",
      "Epoch 114/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.3580e-06 - val_accuracy: 0.9479 - val_loss: 0.1604\n",
      "Epoch 115/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8774e-06 - val_accuracy: 0.9479 - val_loss: 0.1610\n",
      "Epoch 116/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4951e-06 - val_accuracy: 0.9479 - val_loss: 0.1609\n",
      "Epoch 117/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8575e-06 - val_accuracy: 0.9479 - val_loss: 0.1620\n",
      "Epoch 118/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.6615e-06 - val_accuracy: 0.9479 - val_loss: 0.1609\n",
      "Epoch 119/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0963e-06 - val_accuracy: 0.9479 - val_loss: 0.1619\n",
      "Epoch 120/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.7092e-06 - val_accuracy: 0.9479 - val_loss: 0.1626\n",
      "Epoch 121/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4613e-06 - val_accuracy: 0.9479 - val_loss: 0.1628\n",
      "Epoch 122/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.3260e-06 - val_accuracy: 0.9479 - val_loss: 0.1632\n",
      "Epoch 123/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7580e-06 - val_accuracy: 0.9479 - val_loss: 0.1631\n",
      "Epoch 124/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9073e-06 - val_accuracy: 0.9479 - val_loss: 0.1637\n",
      "Epoch 125/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4142e-06 - val_accuracy: 0.9479 - val_loss: 0.1641\n",
      "Epoch 126/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.0633e-06 - val_accuracy: 0.9479 - val_loss: 0.1646\n",
      "Epoch 127/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.3513e-06 - val_accuracy: 0.9479 - val_loss: 0.1654\n",
      "Epoch 128/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4532e-06 - val_accuracy: 0.9531 - val_loss: 0.1645\n",
      "Epoch 129/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9535e-06 - val_accuracy: 0.9531 - val_loss: 0.1644\n",
      "Epoch 130/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8664e-06 - val_accuracy: 0.9479 - val_loss: 0.1657\n",
      "Epoch 131/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.5781e-06 - val_accuracy: 0.9479 - val_loss: 0.1662\n",
      "Epoch 132/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0480e-06 - val_accuracy: 0.9531 - val_loss: 0.1660\n",
      "Epoch 133/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9011e-06 - val_accuracy: 0.9531 - val_loss: 0.1664\n",
      "Epoch 134/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.5025e-06 - val_accuracy: 0.9531 - val_loss: 0.1667\n",
      "Epoch 135/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.7663e-06 - val_accuracy: 0.9531 - val_loss: 0.1668\n",
      "Epoch 136/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9193e-06 - val_accuracy: 0.9531 - val_loss: 0.1667\n",
      "Epoch 137/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2089e-06 - val_accuracy: 0.9531 - val_loss: 0.1680\n",
      "Epoch 138/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4582e-06 - val_accuracy: 0.9531 - val_loss: 0.1682\n",
      "Epoch 139/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7415e-06 - val_accuracy: 0.9531 - val_loss: 0.1682\n",
      "Epoch 140/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.1106e-06 - val_accuracy: 0.9531 - val_loss: 0.1686\n",
      "Epoch 141/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3322e-06 - val_accuracy: 0.9531 - val_loss: 0.1687\n",
      "Epoch 142/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4268e-06 - val_accuracy: 0.9531 - val_loss: 0.1694\n",
      "Epoch 143/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7014e-06 - val_accuracy: 0.9531 - val_loss: 0.1688\n",
      "Epoch 144/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.5054e-06 - val_accuracy: 0.9531 - val_loss: 0.1702\n",
      "Epoch 145/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8961e-06 - val_accuracy: 0.9531 - val_loss: 0.1701\n",
      "Epoch 146/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9341e-06 - val_accuracy: 0.9531 - val_loss: 0.1701\n",
      "Epoch 147/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.7246e-06 - val_accuracy: 0.9531 - val_loss: 0.1714\n",
      "Epoch 148/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.1685e-06 - val_accuracy: 0.9531 - val_loss: 0.1705\n",
      "Epoch 149/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6261e-06 - val_accuracy: 0.9531 - val_loss: 0.1714\n",
      "Epoch 150/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3185e-06 - val_accuracy: 0.9531 - val_loss: 0.1716\n",
      "Epoch 151/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7047e-06 - val_accuracy: 0.9531 - val_loss: 0.1718\n",
      "Epoch 152/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2101e-06 - val_accuracy: 0.9531 - val_loss: 0.1723\n",
      "Epoch 153/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.9676e-06 - val_accuracy: 0.9531 - val_loss: 0.1720\n",
      "Epoch 154/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6491e-06 - val_accuracy: 0.9531 - val_loss: 0.1727\n",
      "Epoch 155/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3702e-06 - val_accuracy: 0.9531 - val_loss: 0.1730\n",
      "Epoch 156/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7209e-06 - val_accuracy: 0.9531 - val_loss: 0.1732\n",
      "Epoch 157/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9410e-06 - val_accuracy: 0.9531 - val_loss: 0.1735\n",
      "Epoch 158/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3859e-06 - val_accuracy: 0.9531 - val_loss: 0.1733\n",
      "Epoch 159/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8287e-06 - val_accuracy: 0.9531 - val_loss: 0.1743\n",
      "Epoch 160/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7051e-06 - val_accuracy: 0.9531 - val_loss: 0.1741\n",
      "Epoch 161/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5982e-06 - val_accuracy: 0.9531 - val_loss: 0.1746\n",
      "Epoch 162/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5414e-06 - val_accuracy: 0.9531 - val_loss: 0.1752\n",
      "Epoch 163/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2924e-06 - val_accuracy: 0.9531 - val_loss: 0.1748\n",
      "Epoch 164/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8250e-06 - val_accuracy: 0.9531 - val_loss: 0.1752\n",
      "Epoch 165/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1521e-06 - val_accuracy: 0.9531 - val_loss: 0.1758\n",
      "Epoch 166/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1610e-06 - val_accuracy: 0.9531 - val_loss: 0.1766\n",
      "Epoch 167/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3398e-06 - val_accuracy: 0.9531 - val_loss: 0.1763\n",
      "Epoch 168/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1180e-06 - val_accuracy: 0.9531 - val_loss: 0.1765\n",
      "Epoch 169/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0356e-06 - val_accuracy: 0.9531 - val_loss: 0.1767\n",
      "Epoch 170/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6035e-06 - val_accuracy: 0.9531 - val_loss: 0.1776\n",
      "Epoch 171/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9731e-06 - val_accuracy: 0.9531 - val_loss: 0.1777\n",
      "Epoch 172/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7434e-06 - val_accuracy: 0.9531 - val_loss: 0.1775\n",
      "Epoch 173/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8732e-06 - val_accuracy: 0.9531 - val_loss: 0.1783\n",
      "Epoch 174/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6591e-06 - val_accuracy: 0.9531 - val_loss: 0.1785\n",
      "Epoch 175/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7265e-06 - val_accuracy: 0.9531 - val_loss: 0.1792\n",
      "Epoch 176/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7473e-06 - val_accuracy: 0.9531 - val_loss: 0.1791\n",
      "Epoch 177/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6052e-06 - val_accuracy: 0.9531 - val_loss: 0.1794\n",
      "Epoch 178/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5588e-06 - val_accuracy: 0.9531 - val_loss: 0.1791\n",
      "Epoch 179/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2866e-06 - val_accuracy: 0.9531 - val_loss: 0.1797\n",
      "Epoch 180/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1715e-06 - val_accuracy: 0.9531 - val_loss: 0.1796\n",
      "Epoch 181/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3090e-06 - val_accuracy: 0.9531 - val_loss: 0.1803\n",
      "Epoch 182/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2541e-06 - val_accuracy: 0.9531 - val_loss: 0.1806\n",
      "Epoch 183/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2446e-06 - val_accuracy: 0.9531 - val_loss: 0.1808\n",
      "Epoch 184/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3080e-06 - val_accuracy: 0.9531 - val_loss: 0.1807\n",
      "Epoch 185/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3845e-06 - val_accuracy: 0.9531 - val_loss: 0.1816\n",
      "Epoch 186/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2791e-06 - val_accuracy: 0.9531 - val_loss: 0.1819\n",
      "Epoch 187/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1796e-06 - val_accuracy: 0.9531 - val_loss: 0.1819\n",
      "Epoch 188/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3307e-06 - val_accuracy: 0.9531 - val_loss: 0.1824\n",
      "Epoch 189/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1078e-06 - val_accuracy: 0.9531 - val_loss: 0.1826\n",
      "Epoch 190/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2000e-06 - val_accuracy: 0.9531 - val_loss: 0.1826\n",
      "Epoch 191/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1612e-06 - val_accuracy: 0.9531 - val_loss: 0.1831\n",
      "Epoch 192/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6236e-07 - val_accuracy: 0.9531 - val_loss: 0.1837\n",
      "Epoch 193/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3562e-07 - val_accuracy: 0.9531 - val_loss: 0.1826\n",
      "Epoch 194/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0271e-06 - val_accuracy: 0.9531 - val_loss: 0.1839\n",
      "Epoch 195/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5543e-07 - val_accuracy: 0.9531 - val_loss: 0.1842\n",
      "Epoch 196/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3754e-07 - val_accuracy: 0.9531 - val_loss: 0.1845\n",
      "Epoch 197/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2041e-07 - val_accuracy: 0.9531 - val_loss: 0.1845\n",
      "Epoch 198/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0389e-06 - val_accuracy: 0.9531 - val_loss: 0.1845\n",
      "Epoch 199/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0514e-06 - val_accuracy: 0.9531 - val_loss: 0.1863\n",
      "Epoch 200/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.9312e-07 - val_accuracy: 0.9531 - val_loss: 0.1862\n",
      "Epoch 201/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.5036e-07 - val_accuracy: 0.9531 - val_loss: 0.1856\n",
      "Epoch 202/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7439e-07 - val_accuracy: 0.9531 - val_loss: 0.1865\n",
      "Epoch 203/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.6644e-07 - val_accuracy: 0.9531 - val_loss: 0.1866\n",
      "Epoch 204/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.4828e-07 - val_accuracy: 0.9531 - val_loss: 0.1866\n",
      "Epoch 205/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.3420e-07 - val_accuracy: 0.9531 - val_loss: 0.1869\n",
      "Epoch 206/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2415e-07 - val_accuracy: 0.9531 - val_loss: 0.1872\n",
      "Epoch 207/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.0694e-07 - val_accuracy: 0.9531 - val_loss: 0.1886\n",
      "Epoch 208/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.8283e-07 - val_accuracy: 0.9531 - val_loss: 0.1888\n",
      "Epoch 209/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.8333e-07 - val_accuracy: 0.9531 - val_loss: 0.1881\n",
      "Epoch 210/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.0783e-07 - val_accuracy: 0.9531 - val_loss: 0.1897\n",
      "Epoch 211/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.6954e-07 - val_accuracy: 0.9531 - val_loss: 0.1890\n",
      "Epoch 212/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5975e-07 - val_accuracy: 0.9531 - val_loss: 0.1892\n",
      "Epoch 213/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.3684e-07 - val_accuracy: 0.9531 - val_loss: 0.1900\n",
      "Epoch 214/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7715e-07 - val_accuracy: 0.9531 - val_loss: 0.1905\n",
      "Epoch 215/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.8911e-07 - val_accuracy: 0.9531 - val_loss: 0.1904\n",
      "Epoch 216/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9198e-07 - val_accuracy: 0.9531 - val_loss: 0.1911\n",
      "Epoch 217/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.4717e-07 - val_accuracy: 0.9531 - val_loss: 0.1906\n",
      "Epoch 218/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.8298e-07 - val_accuracy: 0.9531 - val_loss: 0.1914\n",
      "Epoch 219/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.1125e-07 - val_accuracy: 0.9531 - val_loss: 0.1917\n",
      "Epoch 220/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8702e-07 - val_accuracy: 0.9531 - val_loss: 0.1919\n",
      "Epoch 221/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.0937e-07 - val_accuracy: 0.9531 - val_loss: 0.1925\n",
      "Epoch 222/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5808e-07 - val_accuracy: 0.9531 - val_loss: 0.1928\n",
      "Epoch 223/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.3139e-07 - val_accuracy: 0.9531 - val_loss: 0.1929\n",
      "Epoch 224/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4575e-07 - val_accuracy: 0.9531 - val_loss: 0.1924\n",
      "Epoch 225/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0084e-07 - val_accuracy: 0.9531 - val_loss: 0.1940\n",
      "Epoch 226/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.3115e-07 - val_accuracy: 0.9531 - val_loss: 0.1933\n",
      "Epoch 227/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.3086e-07 - val_accuracy: 0.9531 - val_loss: 0.1949\n",
      "Epoch 228/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.8793e-07 - val_accuracy: 0.9531 - val_loss: 0.1944\n",
      "Epoch 229/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.9228e-07 - val_accuracy: 0.9531 - val_loss: 0.1948\n",
      "Epoch 230/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2875e-07 - val_accuracy: 0.9531 - val_loss: 0.1962\n",
      "Epoch 231/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0961e-07 - val_accuracy: 0.9531 - val_loss: 0.1952\n",
      "Epoch 232/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.4458e-07 - val_accuracy: 0.9479 - val_loss: 0.1961\n",
      "Epoch 233/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.4477e-07 - val_accuracy: 0.9479 - val_loss: 0.1967\n",
      "Epoch 234/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8483e-07 - val_accuracy: 0.9479 - val_loss: 0.1969\n",
      "Epoch 235/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9125e-07 - val_accuracy: 0.9479 - val_loss: 0.1978\n",
      "Epoch 236/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.9112e-07 - val_accuracy: 0.9531 - val_loss: 0.1974\n",
      "Epoch 237/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.8269e-07 - val_accuracy: 0.9531 - val_loss: 0.1969\n",
      "Epoch 238/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9882e-07 - val_accuracy: 0.9531 - val_loss: 0.1982\n",
      "Epoch 239/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5187e-07 - val_accuracy: 0.9531 - val_loss: 0.1982\n",
      "Epoch 240/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6762e-07 - val_accuracy: 0.9531 - val_loss: 0.1982\n",
      "Epoch 241/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7076e-07 - val_accuracy: 0.9531 - val_loss: 0.1992\n",
      "Epoch 242/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2693e-07 - val_accuracy: 0.9531 - val_loss: 0.1982\n",
      "Epoch 243/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6475e-07 - val_accuracy: 0.9531 - val_loss: 0.1994\n",
      "Epoch 244/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2389e-07 - val_accuracy: 0.9531 - val_loss: 0.1991\n",
      "Epoch 245/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4534e-07 - val_accuracy: 0.9531 - val_loss: 0.1999\n",
      "Epoch 246/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2622e-07 - val_accuracy: 0.9531 - val_loss: 0.1994\n",
      "Epoch 247/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3477e-07 - val_accuracy: 0.9531 - val_loss: 0.2004\n",
      "Epoch 248/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0891e-07 - val_accuracy: 0.9531 - val_loss: 0.2003\n",
      "Epoch 249/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5290e-07 - val_accuracy: 0.9531 - val_loss: 0.1999\n",
      "Epoch 250/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0561e-07 - val_accuracy: 0.9531 - val_loss: 0.2003\n",
      "Epoch 251/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1489e-07 - val_accuracy: 0.9531 - val_loss: 0.2011\n",
      "Epoch 252/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4562e-07 - val_accuracy: 0.9531 - val_loss: 0.2009\n",
      "Epoch 253/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0785e-07 - val_accuracy: 0.9531 - val_loss: 0.2012\n",
      "Epoch 254/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7899e-07 - val_accuracy: 0.9531 - val_loss: 0.2015\n",
      "Epoch 255/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2296e-07 - val_accuracy: 0.9531 - val_loss: 0.2021\n",
      "Epoch 256/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6978e-07 - val_accuracy: 0.9531 - val_loss: 0.2014\n",
      "Epoch 257/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0049e-07 - val_accuracy: 0.9531 - val_loss: 0.2019\n",
      "Epoch 258/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7468e-07 - val_accuracy: 0.9531 - val_loss: 0.2018\n",
      "Epoch 259/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5796e-07 - val_accuracy: 0.9531 - val_loss: 0.2026\n",
      "Epoch 260/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6965e-07 - val_accuracy: 0.9531 - val_loss: 0.2024\n",
      "Epoch 261/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5263e-07 - val_accuracy: 0.9531 - val_loss: 0.2029\n",
      "Epoch 262/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3926e-07 - val_accuracy: 0.9531 - val_loss: 0.2030\n",
      "Epoch 263/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.4367e-07 - val_accuracy: 0.9531 - val_loss: 0.2036\n",
      "Epoch 264/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4355e-07 - val_accuracy: 0.9531 - val_loss: 0.2031\n",
      "Epoch 265/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2822e-07 - val_accuracy: 0.9531 - val_loss: 0.2040\n",
      "Epoch 266/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4111e-07 - val_accuracy: 0.9531 - val_loss: 0.2036\n",
      "Epoch 267/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2270e-07 - val_accuracy: 0.9531 - val_loss: 0.2042\n",
      "Epoch 268/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2844e-07 - val_accuracy: 0.9531 - val_loss: 0.2038\n",
      "Epoch 269/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3163e-07 - val_accuracy: 0.9531 - val_loss: 0.2049\n",
      "Epoch 270/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1088e-07 - val_accuracy: 0.9531 - val_loss: 0.2053\n",
      "Epoch 271/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0823e-07 - val_accuracy: 0.9531 - val_loss: 0.2054\n",
      "Epoch 272/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2978e-07 - val_accuracy: 0.9531 - val_loss: 0.2053\n",
      "Epoch 273/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1056e-07 - val_accuracy: 0.9531 - val_loss: 0.2057\n",
      "Epoch 274/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1056e-07 - val_accuracy: 0.9531 - val_loss: 0.2059\n",
      "Epoch 275/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0928e-07 - val_accuracy: 0.9531 - val_loss: 0.2063\n",
      "Epoch 276/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.1650e-07 - val_accuracy: 0.9531 - val_loss: 0.2055\n",
      "Epoch 277/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0782e-07 - val_accuracy: 0.9531 - val_loss: 0.2066\n",
      "Epoch 278/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.0468e-07 - val_accuracy: 0.9531 - val_loss: 0.2066\n",
      "Epoch 279/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2112e-07 - val_accuracy: 0.9531 - val_loss: 0.2069\n",
      "Epoch 280/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.8741e-08 - val_accuracy: 0.9531 - val_loss: 0.2067\n",
      "Epoch 281/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8970e-08 - val_accuracy: 0.9531 - val_loss: 0.2059\n",
      "Epoch 282/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0392e-07 - val_accuracy: 0.9531 - val_loss: 0.2073\n",
      "Epoch 283/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.9484e-08 - val_accuracy: 0.9531 - val_loss: 0.2074\n",
      "Epoch 284/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.3167e-08 - val_accuracy: 0.9531 - val_loss: 0.2077\n",
      "Epoch 285/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7581e-08 - val_accuracy: 0.9531 - val_loss: 0.2073\n",
      "Epoch 286/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.5118e-08 - val_accuracy: 0.9531 - val_loss: 0.2094\n",
      "Epoch 287/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.1858e-08 - val_accuracy: 0.9531 - val_loss: 0.2084\n",
      "Epoch 288/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.9119e-08 - val_accuracy: 0.9531 - val_loss: 0.2077\n",
      "Epoch 289/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.1764e-08 - val_accuracy: 0.9531 - val_loss: 0.2094\n",
      "Epoch 290/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.0687e-08 - val_accuracy: 0.9531 - val_loss: 0.2093\n",
      "Epoch 291/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.5002e-08 - val_accuracy: 0.9531 - val_loss: 0.2088\n",
      "Epoch 292/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4975e-08 - val_accuracy: 0.9531 - val_loss: 0.2099\n",
      "Epoch 293/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8426e-08 - val_accuracy: 0.9531 - val_loss: 0.2095\n",
      "Epoch 294/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.6850e-08 - val_accuracy: 0.9531 - val_loss: 0.2094\n",
      "Epoch 295/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9422e-08 - val_accuracy: 0.9531 - val_loss: 0.2102\n",
      "Epoch 296/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.1531e-08 - val_accuracy: 0.9531 - val_loss: 0.2100\n",
      "Epoch 297/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.7474e-08 - val_accuracy: 0.9531 - val_loss: 0.2107\n",
      "Epoch 298/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7260e-08 - val_accuracy: 0.9531 - val_loss: 0.2110\n",
      "Epoch 299/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8041e-08 - val_accuracy: 0.9531 - val_loss: 0.2120\n",
      "Epoch 300/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1912e-08 - val_accuracy: 0.9531 - val_loss: 0.2111\n",
      "Epoch 301/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1964e-08 - val_accuracy: 0.9531 - val_loss: 0.2114\n",
      "Epoch 302/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.3011e-08 - val_accuracy: 0.9531 - val_loss: 0.2121\n",
      "Epoch 303/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9920e-08 - val_accuracy: 0.9531 - val_loss: 0.2124\n",
      "Epoch 304/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0770e-08 - val_accuracy: 0.9531 - val_loss: 0.2124\n",
      "Epoch 305/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8041e-08 - val_accuracy: 0.9531 - val_loss: 0.2136\n",
      "Epoch 306/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4879e-08 - val_accuracy: 0.9531 - val_loss: 0.2121\n",
      "Epoch 307/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.3109e-08 - val_accuracy: 0.9531 - val_loss: 0.2133\n",
      "Epoch 308/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2601e-08 - val_accuracy: 0.9531 - val_loss: 0.2137\n",
      "Epoch 309/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9736e-08 - val_accuracy: 0.9531 - val_loss: 0.2133\n",
      "Epoch 310/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.9101e-08 - val_accuracy: 0.9531 - val_loss: 0.2147\n",
      "Epoch 311/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4580e-08 - val_accuracy: 0.9531 - val_loss: 0.2147\n",
      "Epoch 312/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2037e-08 - val_accuracy: 0.9531 - val_loss: 0.2151\n",
      "Epoch 313/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4313e-08 - val_accuracy: 0.9531 - val_loss: 0.2153\n",
      "Epoch 314/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7992e-08 - val_accuracy: 0.9531 - val_loss: 0.2149\n",
      "Epoch 315/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8214e-08 - val_accuracy: 0.9531 - val_loss: 0.2156\n",
      "Epoch 316/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7167e-08 - val_accuracy: 0.9531 - val_loss: 0.2146\n",
      "Epoch 317/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2674e-08 - val_accuracy: 0.9531 - val_loss: 0.2153\n",
      "Epoch 318/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0964e-08 - val_accuracy: 0.9531 - val_loss: 0.2157\n",
      "Epoch 319/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.1893e-08 - val_accuracy: 0.9583 - val_loss: 0.2145\n",
      "Epoch 320/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7609e-08 - val_accuracy: 0.9531 - val_loss: 0.2157\n",
      "Epoch 321/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.0054e-08 - val_accuracy: 0.9531 - val_loss: 0.2153\n",
      "Epoch 322/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8999e-08 - val_accuracy: 0.9531 - val_loss: 0.2166\n",
      "Epoch 323/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8537e-08 - val_accuracy: 0.9531 - val_loss: 0.2170\n",
      "Epoch 324/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7647e-08 - val_accuracy: 0.9531 - val_loss: 0.2171\n",
      "Epoch 325/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2132e-08 - val_accuracy: 0.9531 - val_loss: 0.2176\n",
      "Epoch 326/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.4929e-08 - val_accuracy: 0.9531 - val_loss: 0.2179\n",
      "Epoch 327/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.0703e-08 - val_accuracy: 0.9583 - val_loss: 0.2182\n",
      "Epoch 328/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3811e-08 - val_accuracy: 0.9583 - val_loss: 0.2178\n",
      "Epoch 329/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.4500e-08 - val_accuracy: 0.9583 - val_loss: 0.2177\n",
      "Epoch 330/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.6464e-08 - val_accuracy: 0.9583 - val_loss: 0.2177\n",
      "Epoch 331/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2549e-08 - val_accuracy: 0.9583 - val_loss: 0.2179\n",
      "Epoch 332/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.1514e-08 - val_accuracy: 0.9583 - val_loss: 0.2186\n",
      "Epoch 333/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0657e-08 - val_accuracy: 0.9583 - val_loss: 0.2193\n",
      "Epoch 334/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.1557e-08 - val_accuracy: 0.9583 - val_loss: 0.2185\n",
      "Epoch 335/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.9391e-08 - val_accuracy: 0.9583 - val_loss: 0.2187\n",
      "Epoch 336/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3275e-08 - val_accuracy: 0.9583 - val_loss: 0.2199\n",
      "Epoch 337/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1218e-08 - val_accuracy: 0.9583 - val_loss: 0.2199\n",
      "Epoch 338/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1827e-08 - val_accuracy: 0.9583 - val_loss: 0.2198\n",
      "Epoch 339/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.7992e-08 - val_accuracy: 0.9583 - val_loss: 0.2207\n",
      "Epoch 340/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6686e-08 - val_accuracy: 0.9583 - val_loss: 0.2196\n",
      "Epoch 341/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5901e-08 - val_accuracy: 0.9583 - val_loss: 0.2199\n",
      "Epoch 342/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5572e-08 - val_accuracy: 0.9583 - val_loss: 0.2200\n",
      "Epoch 343/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2939e-08 - val_accuracy: 0.9583 - val_loss: 0.2199\n",
      "Epoch 344/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7397e-08 - val_accuracy: 0.9583 - val_loss: 0.2199\n",
      "Epoch 345/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7368e-08 - val_accuracy: 0.9583 - val_loss: 0.2188\n",
      "Epoch 346/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5999e-08 - val_accuracy: 0.9583 - val_loss: 0.2200\n",
      "Epoch 347/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2341e-08 - val_accuracy: 0.9583 - val_loss: 0.2207\n",
      "Epoch 348/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4571e-08 - val_accuracy: 0.9583 - val_loss: 0.2202\n",
      "Epoch 349/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6399e-08 - val_accuracy: 0.9583 - val_loss: 0.2196\n",
      "Epoch 350/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2442e-08 - val_accuracy: 0.9583 - val_loss: 0.2198\n",
      "Epoch 351/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1972e-08 - val_accuracy: 0.9583 - val_loss: 0.2193\n",
      "Epoch 352/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0264e-08 - val_accuracy: 0.9583 - val_loss: 0.2219\n",
      "Epoch 353/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1146e-08 - val_accuracy: 0.9583 - val_loss: 0.2200\n",
      "Epoch 354/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1883e-08 - val_accuracy: 0.9583 - val_loss: 0.2218\n",
      "Epoch 355/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1700e-08 - val_accuracy: 0.9583 - val_loss: 0.2217\n",
      "Epoch 356/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.0833e-09 - val_accuracy: 0.9583 - val_loss: 0.2217\n",
      "Epoch 357/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4307e-09 - val_accuracy: 0.9583 - val_loss: 0.2224\n",
      "Epoch 358/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6716e-09 - val_accuracy: 0.9583 - val_loss: 0.2231\n",
      "Epoch 359/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3779e-09 - val_accuracy: 0.9583 - val_loss: 0.2230\n",
      "Epoch 360/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6127e-09 - val_accuracy: 0.9583 - val_loss: 0.2233\n",
      "Epoch 361/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.5979e-09 - val_accuracy: 0.9583 - val_loss: 0.2241\n",
      "Epoch 362/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0354e-08 - val_accuracy: 0.9583 - val_loss: 0.2237\n",
      "Epoch 363/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3119e-09 - val_accuracy: 0.9583 - val_loss: 0.2249\n",
      "Epoch 364/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.3439e-09 - val_accuracy: 0.9583 - val_loss: 0.2248\n",
      "Epoch 365/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.7345e-09 - val_accuracy: 0.9583 - val_loss: 0.2242\n",
      "Epoch 366/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.7656e-09 - val_accuracy: 0.9583 - val_loss: 0.2246\n",
      "Epoch 367/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4039e-09 - val_accuracy: 0.9583 - val_loss: 0.2239\n",
      "Epoch 368/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8617e-09 - val_accuracy: 0.9583 - val_loss: 0.2253\n",
      "Epoch 369/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8468e-09 - val_accuracy: 0.9583 - val_loss: 0.2245\n",
      "Epoch 370/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7076e-09 - val_accuracy: 0.9583 - val_loss: 0.2245\n",
      "Epoch 371/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7586e-09 - val_accuracy: 0.9583 - val_loss: 0.2250\n",
      "Epoch 372/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9046e-09 - val_accuracy: 0.9583 - val_loss: 0.2255\n",
      "Epoch 373/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2048e-09 - val_accuracy: 0.9583 - val_loss: 0.2246\n",
      "Epoch 374/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7369e-09 - val_accuracy: 0.9583 - val_loss: 0.2251\n",
      "Epoch 375/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.7698e-09 - val_accuracy: 0.9583 - val_loss: 0.2252\n",
      "Epoch 376/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6329e-09 - val_accuracy: 0.9583 - val_loss: 0.2251\n",
      "Epoch 377/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0650e-09 - val_accuracy: 0.9583 - val_loss: 0.2245\n",
      "Epoch 378/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1954e-09 - val_accuracy: 0.9583 - val_loss: 0.2256\n",
      "Epoch 379/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1424e-09 - val_accuracy: 0.9583 - val_loss: 0.2247\n",
      "Epoch 380/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.9481e-09 - val_accuracy: 0.9583 - val_loss: 0.2255\n",
      "Epoch 381/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.1940e-09 - val_accuracy: 0.9583 - val_loss: 0.2259\n",
      "Epoch 382/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.8733e-09 - val_accuracy: 0.9583 - val_loss: 0.2264\n",
      "Epoch 383/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8531e-09 - val_accuracy: 0.9583 - val_loss: 0.2261\n",
      "Epoch 384/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1157e-09 - val_accuracy: 0.9583 - val_loss: 0.2266\n",
      "Epoch 385/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.9255e-09 - val_accuracy: 0.9583 - val_loss: 0.2263\n",
      "Epoch 386/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6158e-09 - val_accuracy: 0.9583 - val_loss: 0.2269\n",
      "Epoch 387/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1369e-09 - val_accuracy: 0.9583 - val_loss: 0.2269\n",
      "Epoch 388/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.8392e-09 - val_accuracy: 0.9583 - val_loss: 0.2268\n",
      "Epoch 389/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4202e-09 - val_accuracy: 0.9583 - val_loss: 0.2270\n",
      "Epoch 390/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.5861e-09 - val_accuracy: 0.9583 - val_loss: 0.2260\n",
      "Epoch 391/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8089e-09 - val_accuracy: 0.9583 - val_loss: 0.2283\n",
      "Epoch 392/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7080e-09 - val_accuracy: 0.9583 - val_loss: 0.2267\n",
      "Epoch 393/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2389e-09 - val_accuracy: 0.9583 - val_loss: 0.2276\n",
      "Epoch 394/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2249e-09 - val_accuracy: 0.9583 - val_loss: 0.2274\n",
      "Epoch 395/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2533e-09 - val_accuracy: 0.9583 - val_loss: 0.2275\n",
      "Epoch 396/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2642e-09 - val_accuracy: 0.9583 - val_loss: 0.2274\n",
      "Epoch 397/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0255e-09 - val_accuracy: 0.9583 - val_loss: 0.2274\n",
      "Epoch 398/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7557e-10 - val_accuracy: 0.9583 - val_loss: 0.2267\n",
      "Epoch 399/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6356e-10 - val_accuracy: 0.9583 - val_loss: 0.2279\n",
      "Epoch 400/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.4432e-10 - val_accuracy: 0.9583 - val_loss: 0.2281\n",
      "Epoch 401/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2522e-10 - val_accuracy: 0.9583 - val_loss: 0.2274\n",
      "Epoch 402/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4381e-10 - val_accuracy: 0.9583 - val_loss: 0.2270\n",
      "Epoch 403/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.1187e-10 - val_accuracy: 0.9583 - val_loss: 0.2281\n",
      "Epoch 404/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4854e-09 - val_accuracy: 0.9583 - val_loss: 0.2286\n",
      "Epoch 405/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8618e-10 - val_accuracy: 0.9583 - val_loss: 0.2288\n",
      "Epoch 406/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1447e-10 - val_accuracy: 0.9583 - val_loss: 0.2276\n",
      "Epoch 407/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4394e-10 - val_accuracy: 0.9583 - val_loss: 0.2280\n",
      "Epoch 408/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.6174e-10 - val_accuracy: 0.9583 - val_loss: 0.2278\n",
      "Epoch 409/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5872e-10 - val_accuracy: 0.9583 - val_loss: 0.2274\n",
      "Epoch 410/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2737e-09 - val_accuracy: 0.9583 - val_loss: 0.2274\n",
      "Epoch 411/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.8442e-10 - val_accuracy: 0.9583 - val_loss: 0.2275\n",
      "Epoch 412/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.5071e-10 - val_accuracy: 0.9583 - val_loss: 0.2275\n",
      "Epoch 413/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1649e-10 - val_accuracy: 0.9583 - val_loss: 0.2275\n",
      "Epoch 414/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8112e-10 - val_accuracy: 0.9583 - val_loss: 0.2267\n",
      "Epoch 415/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7809e-10 - val_accuracy: 0.9583 - val_loss: 0.2279\n",
      "Epoch 416/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4200e-10 - val_accuracy: 0.9583 - val_loss: 0.2278\n",
      "Epoch 417/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0093e-10 - val_accuracy: 0.9583 - val_loss: 0.2278\n",
      "Epoch 418/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0137e-10 - val_accuracy: 0.9583 - val_loss: 0.2282\n",
      "Epoch 419/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6884e-11 - val_accuracy: 0.9583 - val_loss: 0.2279\n",
      "Epoch 420/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2087e-10 - val_accuracy: 0.9583 - val_loss: 0.2272\n",
      "Epoch 421/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2271\n",
      "Epoch 422/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2264\n",
      "Epoch 423/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2263\n",
      "Epoch 424/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2262\n",
      "Epoch 425/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2260\n",
      "Epoch 426/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3264e-11 - val_accuracy: 0.9583 - val_loss: 0.2263\n",
      "Epoch 427/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2258\n",
      "Epoch 428/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2263\n",
      "Epoch 429/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2258\n",
      "Epoch 430/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.9450e-11 - val_accuracy: 0.9583 - val_loss: 0.2263\n",
      "Epoch 431/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2261\n",
      "Epoch 432/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2252\n",
      "Epoch 433/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2256\n",
      "Epoch 434/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2255\n",
      "Epoch 435/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2253\n",
      "Epoch 436/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2252\n",
      "Epoch 437/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2253\n",
      "Epoch 438/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2248\n",
      "Epoch 439/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2247\n",
      "Epoch 440/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2252\n",
      "Epoch 441/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2256\n",
      "Epoch 442/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2263\n",
      "Epoch 443/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2252\n",
      "Epoch 444/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2260\n",
      "Epoch 445/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2254\n",
      "Epoch 446/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2258\n",
      "Epoch 447/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2261\n",
      "Epoch 448/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2250\n",
      "Epoch 449/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2262\n",
      "Epoch 450/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2267\n",
      "Epoch 451/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2267\n",
      "Epoch 452/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2267\n",
      "Epoch 453/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2269\n",
      "Epoch 454/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2265\n",
      "Epoch 455/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2260\n",
      "Epoch 456/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2265\n",
      "Epoch 457/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2265\n",
      "Epoch 458/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2275\n",
      "Epoch 459/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2276\n",
      "Epoch 460/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2268\n",
      "Epoch 461/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2264\n",
      "Epoch 462/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2280\n",
      "Epoch 463/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2274\n",
      "Epoch 464/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2285\n",
      "Epoch 465/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2280\n",
      "Epoch 466/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2286\n",
      "Epoch 467/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2284\n",
      "Epoch 468/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2290\n",
      "Epoch 469/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2286\n",
      "Epoch 470/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2284\n",
      "Epoch 471/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2296\n",
      "Epoch 472/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2283\n",
      "Epoch 473/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2290\n",
      "Epoch 474/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2297\n",
      "Epoch 475/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2300\n",
      "Epoch 476/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2298\n",
      "Epoch 477/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2292\n",
      "Epoch 478/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2298\n",
      "Epoch 479/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2302\n",
      "Epoch 480/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2300\n",
      "Epoch 481/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2307\n",
      "Epoch 482/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2305\n",
      "Epoch 483/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2311\n",
      "Epoch 484/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2307\n",
      "Epoch 485/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2320\n",
      "Epoch 486/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2298\n",
      "Epoch 487/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2312\n",
      "Epoch 488/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2310\n",
      "Epoch 489/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2311\n",
      "Epoch 490/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2315\n",
      "Epoch 491/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2316\n",
      "Epoch 492/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2309\n",
      "Epoch 493/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2309\n",
      "Epoch 494/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2316\n",
      "Epoch 495/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2319\n",
      "Epoch 496/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2308\n",
      "Epoch 497/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2315\n",
      "Epoch 498/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2319\n",
      "Epoch 499/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2315\n",
      "Epoch 500/500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2316\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9547 - loss: 0.2263 \n",
      "Test Loss: 0.2316, Test Accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build Neural Network Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(9,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # 2 output neurons for binary classification\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"/mnt/data/tic-tac-toe.keras\")  # Save as .keras (Keras 3 recommended format)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "\n",
    "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABTHklEQVR4nO3deXwTdf4/8Nfk7EFbCj2BFoochXK3ggXxAgt4Iu4PVpFDYN3KsVbUVUTl8ABdQdavguIqiLrCIuqyCyJFARF0QaAccogIFGlLKUfvJmkyvz8+Tdo0aekxyZT09Xw88qCZzEw+GSt58f4cI8myLIOIiIjIR2jUbgARERGRkhhuiIiIyKcw3BAREZFPYbghIiIin8JwQ0RERD6F4YaIiIh8CsMNERER+RSd2g3wNpvNhqysLAQFBUGSJLWbQ0RERHUgyzIKCwvRpk0baDS112aaXbjJyspCTEyM2s0gIiKiBjh79izatWtX6z7NLtwEBQUBEBcnODhY5dYQERFRXRQUFCAmJsbxPV6bZhdu7F1RwcHBDDdERETXmLoMKeGAYiIiIvIpDDdERETkUxhuiIiIyKc0uzE3RETUeFarFRaLRe1mkI8xGAxXneZdFww3RERUZ7IsIycnB1euXFG7KeSDNBoN4uLiYDAYGnUehhsiIqoze7CJiIhAQEAAF0MlxdgX2c3OzkZsbGyjfrcYboiIqE6sVqsj2LRu3Vrt5pAPCg8PR1ZWFsrLy6HX6xt8Hg4oJiKiOrGPsQkICFC5JeSr7N1RVqu1UedhuCEionphVxR5ilK/Www3RERE5FMYboiIiMinMNwQERHV0y233IK0tLQ673/69GlIkoSMjAyPtYkqMdwopNxqQ9aVUpy9VKJ2U4iIqIIkSbU+Jk6c2KDzfv7553jxxRfrvH9MTAyys7PRo0ePBr1fXTFECZwKrpC8IjMGLvwWOo2EX1+5Q+3mEBERgOzsbMfPa9aswQsvvIDjx487tvn7+zvtb7FY6jQFuVWrVvVqh1arRVRUVL2OoYZj5UYhOq0Y4V1ukyHLssqtISLyDlmWUWIu9/qjrn/PRkVFOR4hISGQJMnxvKysDC1btsS//vUv3HLLLfDz88PHH3+Mixcv4oEHHkC7du0QEBCAnj174tNPP3U6b/VuqQ4dOuCVV17BpEmTEBQUhNjYWCxfvtzxevWKyrZt2yBJEr755hskJSUhICAAAwcOdApeAPDSSy8hIiICQUFBmDJlCp555hn06dOnQf+tAMBkMuEvf/kLIiIi4OfnhxtvvBF79uxxvH758mWMHTsW4eHh8Pf3R+fOnbFixQoAgNlsxvTp0xEdHQ0/Pz906NABCxYsaHBbPImVG4Xoq9wLw2qTHWGHiMiXlVqs6P7C115/3yPzhyHAoMxX2NNPP41FixZhxYoVMBqNKCsrQ2JiIp5++mkEBwdjw4YNGDduHDp27IgBAwbUeJ5FixbhxRdfxLPPPovPPvsMjz76KG666SbEx8fXeMzs2bOxaNEihIeHIzU1FZMmTcLOnTsBAJ988glefvllLF26FIMGDcLq1auxaNEixMXFNfiz/vWvf8W6devw4Ycfon379njttdcwbNgw/Prrr2jVqhWef/55HDlyBF999RXCwsLw66+/orS0FADw5ptvYv369fjXv/6F2NhYnD17FmfPnm1wWzyJ4UYh2iphptwmQ6dVsTFERFRnaWlpGDVqlNO2J5980vHzjBkzsGnTJqxdu7bWcHPHHXdg6tSpAERgeuONN7Bt27Zaw83LL7+Mm2++GQDwzDPP4M4770RZWRn8/Pzwf//3f5g8eTIefvhhAMALL7yAzZs3o6ioqEGfs7i4GMuWLcPKlSsxYsQIAMB7772H9PR0vP/++3jqqaeQmZmJvn37IikpCYCoSNllZmaic+fOuPHGGyFJEtq3b9+gdniD6uFm6dKl+Nvf/obs7GwkJCRgyZIlGDx4cI37m0wmzJ8/Hx9//DFycnLQrl07zJ49G5MmTfJiq13pNJXhxmK1wU/PdENEvs9fr8WR+cNUeV+l2L/I7axWKxYuXIg1a9bg3LlzMJlMMJlMCAwMrPU8vXr1cvxs7/7Kzc2t8zHR0dEAgNzcXMTGxuL48eOOsGTXv39/fPvtt3X6XNWdPHkSFosFgwYNcmzT6/Xo378/jh49CgB49NFHcf/992Pfvn1ISUnByJEjMXDgQADAxIkTcfvtt6Nr164YPnw47rrrLqSkpDSoLZ6marhZs2YN0tLSHCW3d999FyNGjMCRI0cQGxvr9pjRo0fj/PnzeP/999GpUyfk5uaivLzcyy13pddWdkuVWznmhoiaB0mSFOseUkv10LJo0SK88cYbWLJkCXr27InAwECkpaXBbDbXep7qA5ElSYLNZqvzMfbVeaseU33F3saM6bQf6+6c9m0jRozAmTNnsGHDBmzZsgVDhgzBtGnT8Prrr6Nfv344deoUvvrqK2zZsgWjR4/G0KFD8dlnnzW4TZ6i6oDixYsXY/LkyZgyZQq6deuGJUuWICYmBsuWLXO7/6ZNm7B9+3Zs3LgRQ4cORYcOHdC/f39HqlSTViPB/vtiucovMxERNV07duzAvffei4ceegi9e/dGx44dceLECa+3o2vXrti9e7fTtp9++qnB5+vUqRMMBgO+//57xzaLxYKffvoJ3bp1c2wLDw/HxIkT8fHHH2PJkiVOA6ODg4MxZswYvPfee1izZg3WrVuHS5cuNbhNnqJa3Dabzdi7dy+eeeYZp+0pKSnYtWuX22PWr1+PpKQkvPbaa/joo48QGBiIe+65By+++KLLdD47eznRrqCgQLkPUY1OI8FilWG1sXJDRHSt6tSpE9atW4ddu3YhNDQUixcvRk5OjlMA8IYZM2bgT3/6E5KSkjBw4ECsWbMGBw8eRMeOHa96bPVZVwDQvXt3PProo3jqqafQqlUrxMbG4rXXXkNJSQkmT54MQIzrSUxMREJCAkwmE/773/86Pvcbb7yB6Oho9OnTBxqNBmvXrkVUVBRatmyp6OdWgmrhJi8vD1arFZGRkU7bIyMjkZOT4/aY3377Dd9//z38/PzwxRdfIC8vD1OnTsWlS5fwwQcfuD1mwYIFmDdvnuLtd0en0cBitbJbiojoGvb888/j1KlTGDZsGAICAvDII49g5MiRyM/P92o7xo4di99++w1PPvkkysrKMHr0aEycONGlmuPOH//4R5dtp06dwsKFC2Gz2TBu3DgUFhYiKSkJX3/9NUJDQwGIu3LPmjULp0+fhr+/PwYPHozVq1cDAFq0aIFXX30VJ06cgFarxfXXX4+NGzdCo2l6q8pIskqLsmRlZaFt27bYtWsXkpOTHdtffvllfPTRRzh27JjLMSkpKdixYwdycnIQEhICQKwS+Yc//AHFxcVuqzfuKjcxMTHIz89HcHCwop+p59yvUVhWjm+fuBkdw1soem4iIrWVlZXh1KlTiIuLg5+fn9rNaZZuv/12REVF4aOPPlK7KR5R2+9YQUEBQkJC6vT9rVrlJiwsDFqt1qVKk5ub61LNsYuOjkbbtm0dwQYAunXrBlmW8fvvv6Nz584uxxiNRhiNRmUbXwP7oOJydksREVEjlZSU4J133sGwYcOg1Wrx6aefYsuWLUhPT1e7aU2earUkg8GAxMREl/9I6enpNQ4QHjRoELKyspzm+P/yyy/QaDRo166dR9tbF9qK6eAWKwcUExFR40iShI0bN2Lw4MFITEzEf/7zH6xbtw5Dhw5Vu2lNnqrz92bOnIlx48YhKSkJycnJWL58OTIzM5GamgoAmDVrFs6dO4dVq1YBAB588EG8+OKLePjhhzFv3jzk5eXhqaeewqRJk2ocUOxN+opwwwHFRETUWP7+/tiyZYvazbgmqRpuxowZg4sXL2L+/PmOu6Vu3LjRsephdnY2MjMzHfu3aNEC6enpmDFjBpKSktC6dWuMHj0aL730klofwYmuolvKwgHFREREqlF95aWpU6e6rMBot3LlSpdt8fHxTba/0XHzTHZLERERqabpzd+6htlvwcABxUREROphuFGQTsPZUkRERGpjuFGQnt1SREREqmO4URAHFBMR+aZbbrkFaWlpjucdOnTAkiVLaj1GkiR8+eWXjX5vpc7TnDDcKEjrGHPDyg0RUVNw991317guzA8//ABJkrBv3756n3fPnj145JFHGts8J3PnzkWfPn1ctmdnZ2PEiBGKvld1K1eubJL3iGoohhsFVXZLsXJDRNQUTJ48Gd9++y3OnDnj8toHH3yAPn36oF+/fvU+b3h4OAICApRo4lVFRUV5baV9X8FwoyAOKCYialruuusuREREuCwtUlJSgjVr1mDy5Mm4ePEiHnjgAbRr1w4BAQHo2bMnPv3001rPW71b6sSJE7jpppvg5+eH7t27u12y5Omnn0aXLl0QEBCAjh074vnnn4fFYgEgKifz5s3DgQMHIEkSJElytLl6t9ShQ4dw2223wd/fH61bt8YjjzzitHL/xIkTMXLkSLz++uuIjo5G69atMW3aNMd7NURmZibuvfdetGjRAsHBwRg9ejTOnz/veP3AgQO49dZbERQUhODgYCQmJuKnn34CAJw5cwZ33303QkNDERgYiISEBGzcuLHBbakL1de58SUcUExEzY4sA5YS77+vPgCQpKvuptPpMH78eKxcuRIvvPACpIpj1q5dC7PZjLFjx6KkpASJiYl4+umnERwcjA0bNmDcuHHo2LEjBgwYcNX3sNlsGDVqFMLCwvDjjz+ioKDAaXyOXVBQEFauXIk2bdrg0KFD+NOf/oSgoCD89a9/xZgxY3D48GFs2rTJsSpx1fso2pWUlGD48OG44YYbsGfPHuTm5mLKlCmYPn26U4DbunUroqOjsXXrVvz6668YM2YM+vTpgz/96U9X/TzVybKMkSNHIjAwENu3b0d5eTmmTp2KMWPGYNu2bQDEHcz79u2LZcuWQavVIiMjA3q9HgAwbdo0mM1mfPfddwgMDMSRI0fQooVnby7NcKMgx72lWLkhoubCUgK80sb77/tsFmAIrNOukyZNwt/+9jds27YNt956KwDRJTVq1CiEhoYiNDQUTz75pGP/GTNmYNOmTVi7dm2dws2WLVtw9OhRnD592nGfw1deecVlnMxzzz3n+LlDhw544oknsGbNGvz1r3+Fv78/WrRoAZ1Oh6ioqBrf65NPPkFpaSlWrVqFwEDx+d966y3cfffdePXVVx03ng4NDcVbb70FrVaL+Ph43Hnnnfjmm28aFG62bNmCgwcP4tSpU4iJiQEAfPTRR0hISMCePXtw/fXXIzMzE0899RTi4+MBwOlG1pmZmbj//vvRs2dPAEDHjh3r3Yb6YreUguyzpVi5ISJqOuLj4zFw4EB88MEHAICTJ09ix44dmDRpEgDAarXi5ZdfRq9evdC6dWu0aNECmzdvdrr9T22OHj2K2NhYpxs4Jycnu+z32Wef4cYbb0RUVBRatGiB559/vs7vUfW9evfu7Qg2gLiptM1mw/Hjxx3bEhISoNVqHc+jo6ORm5tbr/eq+p4xMTGOYAMA3bt3R8uWLXH06FEA4l6RU6ZMwdChQ7Fw4UKcPHnSse9f/vIXvPTSSxg0aBDmzJmDgwcPNqgd9cHKjVIKz+PpzD/jUYMZP9q+ULs1RETeoQ8QVRQ13rceJk+ejOnTp+Ptt9/GihUr0L59ewwZMgQAsGjRIrzxxhtYsmQJevbsicDAQKSlpcFsNtfp3LLsWq2XqnWZ/fjjj/jjH/+IefPmYdiwYQgJCcHq1auxaNGien0OWZZdzu3uPe1dQlVfszVwJm9N71l1+9y5c/Hggw9iw4YN+OqrrzBnzhysXr0a9913H6ZMmYJhw4Zhw4YN2Lx5MxYsWIBFixZhxowZDWpPXbByoxRJQmzZL+ihOQ1LOSs3RNRMSJLoHvL2ow7jbaoaPXo0tFot/vnPf+LDDz/Eww8/7Phi3rFjB+6991489NBD6N27Nzp27IgTJ07U+dzdu3dHZmYmsrIqQ94PP/zgtM/OnTvRvn17zJ49G0lJSejcubPLDC6DwQCr1XrV98rIyEBxcbHTuTUaDbp06VLnNteH/fOdPXvWse3IkSPIz89Ht27dHNu6dOmCxx9/HJs3b8aoUaOwYsUKx2sxMTFITU3F559/jieeeALvvfeeR9pqx3CjFJ2f40fZUqpiQ4iIqLoWLVpgzJgxePbZZ5GVlYWJEyc6XuvUqRPS09Oxa9cuHD16FH/+85+Rk5NT53MPHToUXbt2xfjx43HgwAHs2LEDs2fPdtqnU6dOyMzMxOrVq3Hy5Em8+eab+OIL5yp/hw4dcOrUKWRkZCAvLw8mk8nlvcaOHQs/Pz9MmDABhw8fxtatWzFjxgyMGzfOMd6moaxWKzIyMpweR44cwdChQ9GrVy+MHTsW+/btw+7duzF+/HjcfPPNSEpKQmlpKaZPn45t27bhzJkz2LlzJ/bs2eMIPmlpafj6669x6tQp7Nu3D99++61TKPIEhhul6P0rfy4vU68dRETk1uTJk3H58mUMHToUsbGxju3PP/88+vXrh2HDhuGWW25BVFQURo4cWefzajQafPHFFzCZTOjfvz+mTJmCl19+2Wmfe++9F48//jimT5+OPn36YNeuXXj++eed9rn//vsxfPhw3HrrrQgPD3c7HT0gIABff/01Ll26hOuvvx5/+MMfMGTIELz11lv1uxhuFBUVoW/fvk6PO+64wzEVPTQ0FDfddBOGDh2Kjh07Ys2aNQAArVaLixcvYvz48ejSpQtGjx6NESNGYN68eQBEaJo2bRq6deuG4cOHo2vXrli6dGmj21sbSXbXWejDCgoKEBISgvz8fAQHByt6btvcVtDAiqX9/oOp99yk6LmJiNRWVlaGU6dOIS4uDn5+flc/gKieavsdq8/3Nys3CrJoxAqSGlZuiIiIVMNwo6DyinDDbikiIiL1MNwoyFoRbiSGGyIiItUw3CioXGuv3LiOcCciIiLvYLhRkFUrBj9prKzcEJHvambzUMiLlPrdYrhRkL1bSstwQ0Q+yL7qbUmJCjfKpGbBvip01VtHNARvv6Agm6Nyw24pIvI9Wq0WLVu2dNyjKCAgoMZbARDVl81mw4ULFxAQEACdrnHxhOFGQTZdxVRwVm6IyEfZ71jd0JswEtVGo9EgNja20aGZ4UZB9soNu6WIyFdJkoTo6GhERETAYrGo3RzyMQaDARpN40fMMNwoyB5udOyWIiIfp9VqGz0ugshTOKBYQXLFzTO1NlZuiIiI1MJwoyBbRbjR2Vi5ISIiUgvDjZIYboiIiFTHcKMknb/4g+GGiIhINQw3CrKPudHLDDdERERqYbhRkr4i3LByQ0REpBqGGwVJjm4ps8otISIiar4YbhQkVVRuDDLDDRERkVoYbpSkF5UbjrkhIiJSD8ONgjQGEW5YuSEiIlIPw42CtBXhxgiGGyIiIrUw3ChIawgAABjYLUVERKQahhsFafxaAAACwXtLERERqYXhRkG6gJYAgBYogWyzqdsYIiKiZorhRkG6gBAAgF6yotxconJriIiImieGGwXp/YJQLotLWl58WeXWEBERNU8MNwoy6LUogBhUXF6cr3JriIiImieGGwXpNBIKZRFuLKWs3BAREamB4UZBkiShUAoEANhKWLkhIiJSg+rhZunSpYiLi4Ofnx8SExOxY8eOGvfdtm0bJElyeRw7dsyLLa5dEUS4kUuvqNsQIiKiZkrVcLNmzRqkpaVh9uzZ2L9/PwYPHowRI0YgMzOz1uOOHz+O7Oxsx6Nz585eavHVFUuiW8pWysoNERGRGlQNN4sXL8bkyZMxZcoUdOvWDUuWLEFMTAyWLVtW63ERERGIiopyPLRarZdafHXFkljITy5juCEiIlKDauHGbDZj7969SElJcdqekpKCXbt21Xps3759ER0djSFDhmDr1q217msymVBQUOD08KQSjeiWkhhuiIiIVKFauMnLy4PVakVkZKTT9sjISOTk5Lg9Jjo6GsuXL8e6devw+eefo2vXrhgyZAi+++67Gt9nwYIFCAkJcTxiYmIU/RzVlWlF5QYmhhsiIiI16NRugCRJTs9lWXbZZte1a1d07drV8Tw5ORlnz57F66+/jptuusntMbNmzcLMmTMdzwsKCjwacEo1ItxoTIUeew8iIiKqmWqVm7CwMGi1WpcqTW5urks1pzY33HADTpw4UePrRqMRwcHBTg9PslduNGbPdn8RERGRe6qFG4PBgMTERKSnpzttT09Px8CBA+t8nv379yM6Olrp5jWYSSfG3GhNDDdERERqULVbaubMmRg3bhySkpKQnJyM5cuXIzMzE6mpqQBEl9K5c+ewatUqAMCSJUvQoUMHJCQkwGw24+OPP8a6deuwbt06NT+GE5vWDwAgWctUbgkREVHzpGq4GTNmDC5evIj58+cjOzsbPXr0wMaNG9G+fXsAQHZ2ttOaN2azGU8++STOnTsHf39/JCQkYMOGDbjjjjvU+giutAYAgGSzqNwQIiKi5kmSZVlWuxHeVFBQgJCQEOTn53tk/M2Cdz7ArJzHURjYHkFPHVT8/ERERM1Rfb6/Vb/9gq+R7JUbKys3REREamC4UZhGVxFuZIYbIiIiNTDcKEzS6gEAGlu5yi0hIiJqnhhuFKbR2cMNKzdERERqYLhRmL1bSiOzckNERKQGhhuFMdwQERGpi+FGYfZuKa1cDjSvWfZERERNAsONwrR6Y+UTDiomIiLyOoYbhen0hsonXOuGiIjI6xhuFGbvlgIAWM3qNYSIiKiZYrhRmE5XpXLDbikiIiKvY7hRmF6vQ7lccVnZLUVEROR1DDcK02s1KIdWPKmtW6r4ImBlZYeIiEhpDDcKM+o0MEMnntTULZV3AvhbR+D9273XMCIiomaC4UZhzpWbGrqlDv5L/Jm1zzuNIiIiakYYbhQmwk1F5aambinZ5r0GERERNTMMNwozOHVL1TSgmCsXExEReQrDjcL0Wgnlsr1bqoYxN7wtAxERkccw3CjMoNXAwm4pIiIi1TDcKMygqzKguKZuKYYbIiIij2G4UZheq4EFV+mW4pgbIiIij2G4UZi+Tt1SDDdERESewnCjMGPVbqnSS+JPazmQf65yJ4YbIiIij9Gp3QBfo9dqYLHPllo/Ayi9DPyyGTjzPTDpayD2BrBbioiIyHMYbhSm10qV3VIAkP5C5c8/rRDhhgOKiYiIPIbdUgoTs6VqyowVFRt2SxEREXkMw43CnGZL1YjhhoiIyFMYbhTmNFuqJuyWIiIi8hiGG4VpNRKsNVVuZHZLEREReRrDjQfYpKuNuWHlhoiIyFMYbjzAqtG7f0FmuCEiIvI0hhsPqLlyY8duKSIiIk9huPEAWXO1AcUMN0RERJ7CRfw8QNJoAKubFw6vA9r2Y7ghIiLyIFZuPMAfNdwwEzLw9bPAhWNebQ8REVFzwnDjAf6SpfYdyq54pR1ERETNEcONB/hdLdxcbUwOERERNRjDjQf41dgtVUG62u0ZiIiIqKEYbjzAD6bad5B42YmIiDyF37IeYMRVuqW4zg0REZHHMNx4wFehY2vfwVZlnjinhRMRESmK4cYDfg3uj+vLlqLAP8b9DnLVcMNbMRARESmJ4cYDDFoNLqAlLFo/9zvYyit/ZrghIiJSFMONB+i1EgDAIhnd7+AUbtgtRUREpCTVw83SpUsRFxcHPz8/JCYmYseOHXU6bufOndDpdOjTp49nG9gABp24rDWHmyrVGlZuiIiIFKVquFmzZg3S0tIwe/Zs7N+/H4MHD8aIESOQmZlZ63H5+fkYP348hgwZ4qWW1o9eKy6rWWNwvwO7pYiIiDxG1XCzePFiTJ48GVOmTEG3bt2wZMkSxMTEYNmyZbUe9+c//xkPPvggkpOTvdTS+jHYw41Uw5ibqgOKOS2ciIhIUaqFG7PZjL179yIlJcVpe0pKCnbt2lXjcStWrMDJkycxZ86cOr2PyWRCQUGB08PT7N1SZtRQubFWWQeHlRsiIiJFqRZu8vLyYLVaERkZ6bQ9MjISOTk5bo85ceIEnnnmGXzyySfQ6ep2f6YFCxYgJCTE8YiJqWF6toLs3VImqaZuKU4FJyIi8hTVBxRLkuT0XJZll20AYLVa8eCDD2LevHno0qVLnc8/a9Ys5OfnOx5nz55tdJuvxhFuaqrcyFzEj4iIyFNUuz11WFgYtFqtS5UmNzfXpZoDAIWFhfjpp5+wf/9+TJ8+HQBgs9kgyzJ0Oh02b96M2267zeU4o9EIo7GGWUseYu+WKqsp3HBAMRERkceoVrkxGAxITExEenq60/b09HQMHDjQZf/g4GAcOnQIGRkZjkdqaiq6du2KjIwMDBgwwFtNvypDxTo3NVZuuM4NERGRx6hWuQGAmTNnYty4cUhKSkJycjKWL1+OzMxMpKamAhBdSufOncOqVaug0WjQo0cPp+MjIiLg5+fnsl1t9m6pMrmmbqmq1RqGGyIiIiWpGm7GjBmDixcvYv78+cjOzkaPHj2wceNGtG/fHgCQnZ191TVvmiJ7t1RxTeGmKnZLERERKUqS5ebVL1JQUICQkBDk5+cjODjYI+/xnwNZmPHpfsyK3I0/5y+pfecnjgNBUR5pBxERka+oz/e36rOlfJG9W6qkTpWbZpUtiYiIPI7hxgOMFd1SJTb91XdmtxQREZGiGG48oLJyw3BDRETkbQw3HqCvmApeXJfKDWdLERERKYrhxgMcs6VsdZiMxsoNERGRohhuPMDeLVVk5VRwIiIib2O48YDKyk1dxtywW4qIiEhJDDceYKio3BRa69ItxXBDRESkJIYbD9Dr6hNu2C1FRESkJIYbD7DPlqpTuOFsKSIiIkUx3HiAUasFAJhkPWRIte/Myg0REZGiGG48QK+zBxoJ0PvXvjPDDRERkaIYbjzAPhUcAGSdX+07c0AxERGRohhuPECnkSBVFG9k7dXCDSs3RERESmK48QBJkhzVG0flJnk6EN3bdWeGGyIiIkUx3HiIfa0bm71y498SaN3ZzZ7sliIiIlISw42H2FcptmqNYoNGD0huLjcrN0RERIpiuPEQ+1o3VnvlRqOrIdywckNERKQkhhsPsY+5cYQbbU2VG4YbIiIiJTHceIh9zI3JP0JsCAxjtxQREZEXMNx4iH3MzW+9ngBGrwK63QNoGG6IiIg8rS43P6IGsHdLlepDgfh7xUZ3lRvOliIiIlIUKzceYh9QbLZWqcywW4qIiMjjGG48xN4tZS5nuCEiIvImhhsPsXdLWZwqN1rXHTlbioiISFEMNx5icBtuWLkhIiLyNIYbD2G3FBERkToYbjzE3i1ltlbpdrLfKtwJu6WIiIiUxHDjIe7H3HCFYiIiIk9juPEQt91SGncDitktRUREpCSGGw8xVKxzw8oNERGRdzHceEjlmBsOKCYiIvImhhsPsXdLWcqrDihmuCEiIvK0BoWbs2fP4vfff3c83717N9LS0rB8+XLFGnatq6zcWCs3ulvEj7OliIiIFNWgcPPggw9i69atAICcnBzcfvvt2L17N5599lnMnz9f0QZeq+yVG5OF3VJERETe1KBwc/jwYfTv3x8A8K9//Qs9evTArl278M9//hMrV65Usn3XLD+9qNKUOS3i52adG4YbIiIiRTUo3FgsFhiNRgDAli1bcM899wAA4uPjkZ2drVzrrmH+9nBjqdotxdlSREREntagcJOQkIB33nkHO3bsQHp6OoYPHw4AyMrKQuvWrRVt4LXK3yAu7dXDDSs3RERESmpQuHn11Vfx7rvv4pZbbsEDDzyA3r17AwDWr1/v6K5q7vx0bio3bhfxY+WGiIhISbqGHHTLLbcgLy8PBQUFCA0NdWx/5JFHEBAQoFjjrmV+BhFkSq9WueFsKSIiIkU1qHJTWloKk8nkCDZnzpzBkiVLcPz4cURERCjawGuVvXJTama3FBERkTc1KNzce++9WLVqFQDgypUrGDBgABYtWoSRI0di2bJlijbwWuVvsHdLcSo4ERGRNzUo3Ozbtw+DBw8GAHz22WeIjIzEmTNnsGrVKrz55puKNvBaVffZUgw3RERESmpQuCkpKUFQUBAAYPPmzRg1ahQ0Gg1uuOEGnDlzRtEGXqv89HWdLcUxN0REREpqULjp1KkTvvzyS5w9exZff/01UlJSAAC5ubkIDg6u17mWLl2KuLg4+Pn5ITExETt27Khx3++//x6DBg1C69at4e/vj/j4eLzxxhsN+QgeZ6/clFqskO0BhpUbIiIij2tQuHnhhRfw5JNPokOHDujfvz+Sk5MBiCpO375963yeNWvWIC0tDbNnz8b+/fsxePBgjBgxApmZmW73DwwMxPTp0/Hdd9/h6NGjeO655/Dcc881yXtaGSvCjU2ucmdwhhsiIiKPk2S5Yf0iOTk5yM7ORu/evaHRiC/t3bt3Izg4GPHx8XU6x4ABA9CvXz+nQcjdunXDyJEjsWDBgjqdY9SoUQgMDMRHH33k9nWTyQSTyeR4XlBQgJiYGOTn59e7ylQf5nIbujz3FQDgwJwUhPjrgX0fAeunO+941xtA0iSPtYOIiMgXFBQUICQkpE7f3w2q3ABAVFQU+vbti6ysLJw7dw4A0L9//zoHG7PZjL179zq6tOxSUlKwa9euOp1j//792LVrF26++eYa91mwYAFCQkIcj5iYmDqdu7H0WgmailtJOcbduF3Ej5UbIiIiJTUo3NhsNsyfPx8hISFo3749YmNj0bJlS7z44ouw2er2ZZ2Xlwer1YrIyEin7ZGRkcjJyan12Hbt2sFoNCIpKQnTpk3DlClTatx31qxZyM/PdzzOnj1bp/Y1liRJrjOmOKCYiIjI4xq0QvHs2bPx/vvvY+HChRg0aBBkWcbOnTsxd+5clJWV4eWXX67zuaRqd8qWZdllW3U7duxAUVERfvzxRzzzzDPo1KkTHnjgAbf7Go1Gx00+vc3foEWx2Vq5SjHDDRERkcc1KNx8+OGH+Mc//uG4GzgA9O7dG23btsXUqVPrFG7CwsKg1WpdqjS5ubku1Zzq4uLiAAA9e/bE+fPnMXfu3BrDjZqM1Vcp5oBiIiIij2tQt9SlS5fcjq2Jj4/HpUuX6nQOg8GAxMREpKenO21PT0/HwIED69wWWZadBgw3JS6rFLurSDHcEBERKapBlZvevXvjrbfeclmN+K233kKvXr3qfJ6ZM2di3LhxSEpKQnJyMpYvX47MzEykpqYCEONlzp0757jVw9tvv43Y2FhHsPr+++/x+uuvY8aMGQ35GB7nspCf5GZAMW+cSUREpKgGhZvXXnsNd955J7Zs2YLk5GRIkoRdu3bh7Nmz2LhxY53PM2bMGFy8eBHz589HdnY2evTogY0bN6J9+/YAgOzsbKc1b2w2G2bNmoVTp05Bp9Phuuuuw8KFC/HnP/+5IR/D46ou5AeA3VJERERe0OB1brKysvD222/j2LFjkGUZ3bt3xyOPPIK5c+figw8+ULqdiqnPPPnGGvf+/7DjRB4Wj+6NUf3aAUf/C6wZ67zT7fOBQY95tB1ERETXuvp8fzeocgMAbdq0cRk4fODAAXz44YdNOtx4k1+dKjfsliIiIlJSgxfxo6urXOemouuJi/gRERF5HMONB7kOKOaYGyIiIk9juPGgAIPo9SssKxcb3C5OyG4pIiIiJdVrzM2oUaNqff3KlSuNaYvPiQgWKyNfKKxYh4djboiIiDyuXuEmJCTkqq+PHz++UQ3yJZFBfgCA3MIysYHdUkRERB5Xr3CzYsUKT7XDJ9krN+cL7OHG3YBiVm6IiIiUxDE3HhQZLCo35wvcdEtpKnIlKzdERESKYrjxIHu3VH6pRcyYqhputAbxJ8MNERGRohhuPCjYXwejTlziC4WmauFGX/EDu6WIiIiUxHDjQZIkVemaKnNexE8rxuOwckNERKQshhsPiwiyDyo2Oa9zw24pIiIij2C48bDwinBzsbiGbinOliIiIlIUw42H2VcpLjFzQDEREZE3MNx4mL9BXOLS6uFGZw83rNwQEREpieHGw+yVm1KL1XkRP3vlhrOliIiIFMVw42F+ehFoXCo37JYiIiLyCIYbDwswiHDjOubGPqCY4YaIiEhJDDceZg83pZbyGio37JYiIiJSEsONhzl1S2mqhhsu4kdEROQJDDcexm4pIiIi72K48TD/ispNjTfO5GwpIiIiRTHceJh/TZUbHWdLEREReQLDjYdVXefm+18vVr7AqeBEREQewXDjYf5VBhQ/vvZw5QuOcKNCo4iIiHwYw42H2QcUXyw2O7/AAcVEREQewXDjYfap4ACgQZUgo2G4ISIi8gSGGw+zV24AQFO1D0pj385+KSIiIiUx3HiYf5XKTSH8K1/QB4g/WbkhIqKmyFQE5B513ibLgLm4cnX9wvPAxZPi+ZWzQN6vgLkEKCvwfnur0Kn67s2ARiPBqNPAVG5DEQIwxvQ85o3shXjbr2IHhhsiIvK2kkviEdxGjAE9txcovQz8/hNQdgXIOQxk7QesJrF/dG/A0EJsN+UDrTsDxiAga5/78we3BWYe8drHqY7hxgsCDFqYykWI+Z/cDZfC+gEXfhMv8t5SRESNZ7MBBb8DLWPdv24uAYoviNetFuDUd0D2fqBVR6DTUDEO0hBQ87khA3m/AAFhQItwj32MRjEVATYLkHMIsJQCReeBS6fEP6IlDXDoMxFmZCvw+x5xjEYnPnt5ae3nzj7g/PziCdd9JA0gaUUbrGbX172I4cYL/PVaXIbF8dxilSsX9GPlhojo6kouAQVZQHmZqCxcOgUU54m/QzU64OfPgQvHxL7h3URVQZLEa2UF4jWbBWjdCSi9ApTkub5HiyggpJ04Z3mZ2FZ0XlQ0gMq/r9tdLyoZnYcBYZ2AwAjAXCSW+LCVi/cuviAqHQGtav9csgxYSgBDoPM2SRKf+fT3QMlF0RUEWby3X0sRtA79Czj/MxDVS7z/r1uufh3zMyt/NrQQx9nKxTn9QoCwLiLwtb4O0PlVhMAMoM9YEQxbdRRVmd+2iet53RDxWc/tBbrfCxiDRbXHPmlGJQw3XuBfZVAxAFjKbeIXF2C4ISLfl3tUfAmHd624abAMHFoLtE0Sq7X/+o348m7VUfxpswA2K5B3AvALBi79JioNdf378sLRml+7WDEkICBMBJRT34n3A4CiHPGoidYovrh/3yMee/5x9ba06StChF8IEBgO6IxAULT4rKe/B479Fyg4J0KYfygQFAVc/A2wFNftswLi+lTn30pcb/9W4r0LswBIIsh0uBHoNwEIjhb/bcwlQJs+VSa6VJE4wf179h5T+XNwNBDdq/K5Vv1ooX4LmgH7KsV25bYq4YazpYjIlxRdAH7ZJCofJ78FMn8ESi8pc259gAgBgWGiWhKZIL6Qc48CmT8AcTeLL9rrhlSuJVaWL8JT5xSg6wjg+EbAVAj0GgP4txSvW8rE/pdPAfnnRAVGZwDO7hbVk6SHRWWjRYSoUvyyCcjKAH7bChTlisqLCwmALMat1IWtXJy7+ILz9rCuoopiCBRdTZk/iEpU605AZHeg+0jg5DfA73uBHvcBUb2BuJsqb/FzNRHd6rbfNYbhxgvatPTDoXP5judmp24phhsiakLKzTV/MdpsgKbKJNu9K0Ww0PtXzJixASfSKwehVtWqI5D/u/NYDP9WgLEFEHODCAhl+UBYZ1G1ObNLjIFpEQV0GAQkjBJdRkCVfxxWYbVUBprq+j5U+XOfB51f8wsRD0B0IbVNrHztuttczxUUBSROBKrsBlOhGGtiKhTXrvgiEBQpZg+d/Kai26qwIgiVAheOi+6uiO5A93uAFpEiBIa0FZ+9ZazoYmrZHuj9R+fPa7OJ61y1OtL9HvefuxljuPGCCQM74OufzzueW8ptEKke7JYiInVc+EV0kQDArjfFF/PFX0VFostw8Zq5WASMkHbA+SOiEhPWRXRrZGeIcRbuRPYQX8xhnYA2/YCQGKBdIlBuEv+wu3BcVB70fsp9npqCjTcYg8Sf9gHJ/qHiz8ju4lEXbfs5P2+X5H4/jQZcxeXqGG68ILlja6R0j8TmIyLglFf91w8rN0SktHKz6N44sxM4t090t7TuJCoUNmtFN8aemo8/vqHm1/KOi0dVGh1w01/Fl3u7/kBMf/fVFXuYiupR/89EVA8MN14gSRKWPZSI1I/3Iv3IedEtpeVsKSKqJ5tVzNwxBIrpvuFdxcyf84dFteT3PcCRL0XXkH22T1206w90u1uMX/FvJcJLYLgYCFuYA/zwtggkKS+Jwavn9okZS+UmYOB0QB8IhHfx0Icmqj+GGy/RaiTHfaYs5TbAWKVbSpbFv7JaRKjYQiJqMgqyxTiMkovA5dNiRs1v20SwMNVj5deIBDG4tGUscOVMZeAJ7QD0flDMEio3ifEw7iotdoOfqBzj0bYf0PMPDfxgRN7BcONFeo34y0PMlrL3mcrAplnA/5YBo/4B9Pp/6jWQiLyrOE+s19K2nwgvuUdEVeTnzxt2Po1OVGGGzhF/ahQam9EEpvYS1Qd/Y71IX9EV5bKI3/+WiZ/Tn2e4IfJFpiIxS8jQQkzlzT8rpief2CwWUbNPG3bHGCJWlL35r2Kqc2QCUJgtFkvLOQi0uk6EmpyDYnaPu7VKiJoZhhsv0utE5cZc42ypWsrCRNT0HdsAfPsy0GOUqMr8ukWEjbxfRPezzljDWBhZDPa9bohYHj+sC3DuJ6DHH0S3kmxzDi32WwzE3VS5Leh2j340omsJw40X6SpKxE7dUlXDjcTpfURNkqlIrEvi1xI4/Z0YE2OqWEjt1HYg95gYhFtWsZ7Vtz+7P095mZgm3DJW3M8oNlmsq1KYU7HcvbFy36orw0qsxhDVB8ONFxl0Vbql7H+JlVdZ7Kq2AX1E5HmyLNZuOfSZWIZflkV3j7vl7WvTMlYElhsfFwODg6LErQZKL4vBu9UXybva/YeIqF5UDzdLly7F3/72N2RnZyMhIQFLlizB4MGD3e77+eefY9myZcjIyIDJZEJCQgLmzp2LYcOGebnVDaPXVumW0vuLjZaqd2JluCHyqLICUYEpzhML1mX+KKY05x4RK9zmn736OYLbVt4v6PhXQEComE0U1lWcq8NgccNBS3Hl4m52QZGe+FREVI2q4WbNmjVIS0vD0qVLMWjQILz77rsYMWIEjhw5gthY19vWf/fdd7j99tvxyiuvoGXLllixYgXuvvtu/O9//0Pfvn1V+AT149QtpatYmbNq/zsrN0SNI8tiwG7pFVF5yfyfWEk3KEp0GeUeA8pLr3YWIOE+0WVks4pKS7vrxZiX338C4gZXVl6t5eJPd7OJqgcbIvIaVcPN4sWLMXnyZEyZMgUAsGTJEnz99ddYtmwZFixY4LL/kiVLnJ6/8sor+Pe//43//Oc/NYYbk8kEk6my66egoB5rRCjM0S1VLosbwAHOlRuGG6LanT8ibnaYfQC4kin+zPtF3N+oRQQACbh00vW4C8ecnwdGiBsGhnURY90iu4s7NQdFiYpM6+vcv3/noc7POUWaqElS7f9Ms9mMvXv34plnnnHanpKSgl27dtXpHDabDYWFhWjVqub+6gULFmDevHmNaqtS7N1SFqut8p4q7JYicnVuL3Byq7ix4Onvgd93i/sc5R6p+ZhLReJPnZ8Y6BsUJY4PihZjXSLiRZdSzAD+Q4LIx6kWbvLy8mC1WhEZ6dwHHRkZiZycnDqdY9GiRSguLsbo0aNr3GfWrFmYOXOm43lBQQFiYmIa1uhGsndLma3sliJyMJcA218FbOUi7B/5UqzMWxutUYSV8Hgx+yj+LnEnaqtFhBcO0CVq1lSvqUrVvtBlWXbZ5s6nn36KuXPn4t///jciImq+bYHRaITRaKzxdW/SV3RLlVtl9wOKORWcmoP8c8DxjcCRfwMXT4rlEIqq/4NGAqJ7i4G/5iKx4m5AmFjAruSSuNu0/c7LRETVqBZuwsLCoNVqXao0ubm5LtWc6tasWYPJkydj7dq1GDp0aK37NiUGp26pinAjW6vswcoN+RCbDSg4J2YlndgsupQunxF3qHZHoxeDdQekAu0HigG5siweVW8jUNN4GCKiCqqFG4PBgMTERKSnp+O+++5zbE9PT8e9995b43GffvopJk2ahE8//RR33nmnN5qqGOduKX/XHdgtRdcaS6noIgKA374FTu0Q06kvnQLyfweKc2s+1q8lcP0UMa26wyD3lRhJ4v8XRFRvqnZLzZw5E+PGjUNSUhKSk5OxfPlyZGZmIjU1FYAYL3Pu3DmsWrUKgAg248ePx9///nfccMMNjqqPv78/QkJCVPscdeXULaUzwvV+MvxLnK4BZ3aJ2wyc/1kM9vVvCWgNokpTnUYHhMQAsTeI9V/8Q0Xo6TVa3G6AwYWIPEDVcDNmzBhcvHgR8+fPR3Z2Nnr06IGNGzeiffv2AIDs7GxkZmY69n/33XdRXl6OadOmYdq0aY7tEyZMwMqVK73d/Hpz6paSJNE1ZSmp3IF/0VNTcfEkYCoUa7yc2SnGuZRcBLL2Az9/AadQXnxB/GkMAbrdJVbkbRkrupXi76qcGUhE5CWqDyieOnUqpk6d6va16oFl27Ztnm+QB9m7pSzWivtJ6fyqhRsOKCaV2GzAlTPilgF5x4H/zqw2HqyaLiPE725IDNBlGGBsAcTcABgCvNdmIqIaqB5umhN91XtLAaJy47RYKis35GGmIjHA90qm6Fb6bau4CWTpZcBc6P6YwHAxc8kYLNaNaZ8MdLjRu+0mIqoHhhsvclrED6hc68aOlRtSis0GFGaLSkz2fuDYRvH84q+A1ez+GK0BCGkn/ux4C3D7i0DB70BQG3YtEdE1heHGi/Taat1S+mol/OIL4l44sQO83DK6Zl08CZw/LG4IWV4mZikVZgMn0muvxLRsD4S2F9Osr2QCyVOBbvcAWr3zvq06ev4zEBEpjOHGiyrDjb1bqtq/hotygA9SgIc3idI/UVVl+cCBNRV3tc4FftsmgklNNDpxDyW9H9BvPBDVU9x+IDyeg9eJyKcx3HjRVbul7E5+y3DTXNlsIrz4hYjwsvtdsaKvpAEunxa3GHAiAZE9gIBQsd5MiwgRYGJvAOJu5o0diahZ4t98XuTaLeVmIT8AzmvfkM8qN4sZSsV5wLH/iunWZ3aKbTVp3UmMh7GaxYyldkkVd8MmIiI7hhsvsoeb8qqzpch3lZvFGBZTgRgLc/FX4MJxoCCrMsTItpqPD4oGetwPtB8kfldC2gGtrnO+FQEREblguPEie7eU2dEtxXDjc/J+BU5/J+50veN1McW6NvpAMf4lqpe4r1JkAtDxVjE4ODCcY2OIiBqA4caLXLulahhzI7NbqskryAZyfxZVmIIs4Oz/xG0Jysvc72+foRTeVVRz4u8SY2WComoIMMEebT4RkS9juPEie7ixyYDVJkNbfSo4NT2WMjGQ11YOnPtJBBlTIbB7udjmTpu+4hYEYV1EeLFXZYiIyCsYbrzI3i0FAOZyG/xrmi3FAcXqsJSJGUo/vQ+07iwqLP97Fygvdb9/685AaAcguI24l1JoB7E94T5Ao/VSo4mIqDqGGy8y6iq/8MzlNvjXNKC4phVkSTnlZiBzF5B9UCx6d+mUCDb2IHNic+W+On8xFbttPyCsM2CzAjEDgD4PckwMEVETxHDjRXqtBEkSQ2pMVmvNs6UsNYzboPorvQLk/y4WSDx/BDjwKVBuAsquiLtcVxcULbqRyvIBczGQOAG4fgpDDBHRNYThxoskSYJRp0GZxQaTxSbGZbhTUzcI1cxmA07vEONgco8Cv+8RFbDftgOWYvfHBEaIxRJbxopZS90qBvkyyBARXdMYbrzMqNOKcFNuE2M13LEw3NTKZhVjWg6uBY79Bzj9vfsqTFWB4UBEt8ouputuBRIfBnQG77SZiIi8huHGy4w6MWPKVG6tJdywW8pBloFT24ELv4jbEpz8BsjaL6ouxbmu+weGi1V8g6Iru5W63sFqDBFRM8Jw42UGR7ixAUE1hJvm2C1lrZhqfegzIKCVqF6d2ytW9S0677q/Pdj0eQiIv1N0QYXHAxHx3m03ERE1OQw3Xuao3FhsNS/iZykFvn0ZCI4GkiZ5sXVeIMvA0f8AGf8E8s+KtWAkCfj5S0C21nxc1ztEVSa6NxCbLNabCYoConp4relERHRtYLjxMvt0cMctGNzJygAyfxA/9x3f9O/sLMtidpF/S+DsbuDCMXETSL2/qLxkHwD8WwE2C1CYA5w/XHls1Z8BoNPtwKXfxPTsm54CdEaxqm+noc77RXb3+MciIqJrUxP/1vQ9Rr29clNLlaJqt1RhlpjNo5bSK2LqdGA4kPGJCCzh8cDOvwOQRfj49VvRTv9WQOmlq59TawBumApE9wKObwKMLYBeY8SAX78QMfOpvBQwBHr60xERkQ9iuPEyY9UxN3Vx+Uzdw421vH5VHvu4Fq0RiLkeyDksxruc3iluOXD2R+DXLWJfnV/N902yK70EaHSi26hFpLgbdstYoG0SYCkR59AZgbibgBYR4pge97ueR6NhsCEiogZjuPEye7eUI9yM+wL4z2PAlUz3B1w5A6CG+xLZbIC5EPj2JdHd8+s3QN+xwPCFgLlIVEFObBH7RPcRg3UtxYDVApzbB+QcFPsBYuxL3i81N7x6sPFvJSourTsBxmCg/yOiqhPcFgiqYf0eIiIiL2C48TKnqeAAcN1tQNohYG6I+wMun6n8uawAOLhGVFXCuwLfLwEunXTef/dy8QCAVte5vl6TqsFGawQSRgJ+LYF+44GQtkDuMaBljLhFQUBroMtwTq8mIqImieHGywxVZ0vVRc5B4Mi/gW2vArk/1+/Nqgeb6N5iBd4Lx4Euw8QjqhdwfKO4x1KHQSJMtUsS41+qap8s/uz7UP3aQERE5GUMN15Wp9lSVf2ySTzsgtuJ1XXP/yzGr3S+HYgdKH6O6C5W6z30LyCmv+iSAoBRy8VYGEOA+/eIv1M8ACCugR+MiIioiWC48TL7bKmCUgv+75sTuDU+Aj3a1tAlVVVkD6DXaKDvODHotyadh4oHIG74SERE1Mww3HiZfczN0m2iy+izfb9j+1O3ut854T5gUBoQ2l6Mf+EYFyIioqtiuPEye7eU3ZmLJTXv3PsBoE0fzzaIiIjIx2jUbkBzY6/c2MVHBdW8s3+oh1tDRETkexhuvMw+5sZOqq2ryb+WsTVERETkFsONlxm0zpfcYp81NW03kPIy8OcdlS8GhnmxZURERL6BY268zKh3HnNjtq9UHN5VPADgnrfEHbL9W3q3cURERD6A4cbLqo+5sbhb76bfOC+1hoiIyPewW8rL6hRuiIiIqMEYbrys+lRwc13vDk5ERER1wnDjZdVnS9X5NgxERERUJww3XubaLSWr1BIiIiLfxHDjZdXDjdUmw2pjwCEiIlIKw42XmctdgwwHFRMRESmH4cbLdFrXFYk57oaIiEg5DDdeltQ+FA/0j8Hzd3V3bLNwxhQREZFiGG68TJIkLBjVC5NvjINOI6o4HFRMRESkHIYbFRkqBhdzrRsiIiLlqB5uli5diri4OPj5+SExMRE7duyocd/s7Gw8+OCD6Nq1KzQaDdLS0rzXUA/QV9xEk2NuiIiIlKNquFmzZg3S0tIwe/Zs7N+/H4MHD8aIESOQmZnpdn+TyYTw8HDMnj0bvXv39nJrlWcPN5wtRUREpBxVw83ixYsxefJkTJkyBd26dcOSJUsQExODZcuWud2/Q4cO+Pvf/47x48cjJCTEy61VnkFrH3PDcENERKQU1cKN2WzG3r17kZKS4rQ9JSUFu3btUux9TCYTCgoKnB5NhX3MTZnFhrOXSlRuDRERkW9QLdzk5eXBarUiMjLSaXtkZCRycnIUe58FCxYgJCTE8YiJiVHs3I1l75aa/cUhDH5tK9b+dFblFhEREV37VB9QLEnOi9rJsuyyrTFmzZqF/Px8x+Ps2aYTIOzh5kRuEQDg1U3H1GwOERGRT9Cp9cZhYWHQarUuVZrc3FyXak5jGI1GGI1Gxc6nJEO1+0xxSjgREVHjqVa5MRgMSExMRHp6utP29PR0DBw4UKVWeZdByzuEExERKU21yg0AzJw5E+PGjUNSUhKSk5OxfPlyZGZmIjU1FYDoUjp37hxWrVrlOCYjIwMAUFRUhAsXLiAjIwMGgwHdu3d39xZNml7n3P3GWVNERESNp2q4GTNmDC5evIj58+cjOzsbPXr0wMaNG9G+fXsAYtG+6mve9O3b1/Hz3r178c9//hPt27fH6dOnvdl0RVSv3JTbWLkhIiJqLFXDDQBMnToVU6dOdfvaypUrXbbJsu8EAL1W9fHcREREPoffrirS63j5iYiIlMZvVxUZ3VRufKkyRUREpAaGGxW565Yqs3BQMRERUWMw3Kio+mwpALhSalahJURERL6D4UZF7io3+aUWFVpCRETkOxhuVFR9hWIAyC9huCEiImoMhhsVVV/nBgCusHJDRETUKAw3KnLXLVXAcENERNQoDDcqctctVWqxqtASIiIi38Fwo6IgP9cFootM5Sq0hIiIyHcw3KgoPirYZVuJiZUbIiKixmC4UVF8VJDLtmIzKzdERESNwXCjokCja7dUMbuliIiIGoXhpokpNrNbioiIqDEYblT21oN9YdBqcEvXcABACSs3REREjeLaL0JedVevNhiWEIXNP5/HtuMXUMwBxURERI3Cyk0ToNdqEGDUAuCAYiIiosZiuGkiWlQMLi7hmBsiIqJGYbhpIgIMonLDRfyIiIgah+GmiQg0VFRuGG6IiIgaheGmibCveVNiscJmk1VuDRER0bWL4aaJCKwYUCzLvHkmERFRYzDcNBH+ei0kSfzMGVNEREQNx3DTREiSVGXcDSs3REREDcVw04TYZ0yxckNERNRwDDdNiH1QMVcpJiIiajiGmyakVaABAHCh0KRyS4iIiK5dDDdNSHSIHwAgO79U5ZYQERFduxhumpA2Lf0BAFlXylRuCRER0bWL4aYJacPKDRERUaMx3DQh0fbKTT4rN0RERA3FcNOEtAkR4Sb7Cis3REREDcVw04REtxTdUheKTDCX21RuDRER0bWJ4aYJaR1ogEGngSwD5wvYNUVERNQQDDdNiCRJjungWeyaIiIiahCGmyamcq0bVm6IiIgaguGmiXGsdcPp4ERERA3CcNPEVM6YYuWGiIioIRhumhj7jCku5EdERNQwDDdNjL1yw1swEBERNQzDTRPDyg0REVHjMNw0MdEVlZvLJRYUm8pVbg0REdG1h+GmiQnx1yM8yAgAOJZTqHJriIiIrj0MN01Qz7YhAICfs/JVbgkREdG1R/Vws3TpUsTFxcHPzw+JiYnYsWNHrftv374diYmJ8PPzQ8eOHfHOO+94qaXe06NNMADg8DmGGyIiovpSNdysWbMGaWlpmD17Nvbv34/BgwdjxIgRyMzMdLv/qVOncMcdd2Dw4MHYv38/nn32WfzlL3/BunXrvNxyz0qoqNx890seLFbeQJOIiKg+JFmWZbXefMCAAejXrx+WLVvm2NatWzeMHDkSCxYscNn/6aefxvr163H06FHHttTUVBw4cAA//PBDnd6zoKAAISEhyM/PR3BwcOM/hAecLyjDja9+C4tVRlgLI7pFByEq2A8RwUYEGHQw6jTw02vhp9fCX6+FTitBI0nQagCNZP9ZqvgZ4ueK51pJgiS5vqd9mwTJdVttr1V7XnVr1W2V+0lOz2s6P3mPu98HIl/F33fv0GokxwQZpdTn+1un6DvXg9lsxt69e/HMM884bU9JScGuXbvcHvPDDz8gJSXFaduwYcPw/vvvw2KxQK/XuxxjMplgMpkczwsKChRovWdFBvvh73/si9lfHEJekQk7TpiufhAREVETERFkxO7ZQ1V7f9XCTV5eHqxWKyIjI522R0ZGIicnx+0xOTk5bvcvLy9HXl4eoqOjXY5ZsGAB5s2bp1zDveSOntEY0i0CGZlXkHmpBOcLypBXZEap2YpSixVlFivKym0oM1tRbrPBKgM2mwybLMNqkyHLgFUWz8V2wFrxOgBUrdfJcN5mf8m5plfTPrLTc6d9qr/m9J41H0/eo17dtnmT+RuvCv6+e49Rr+6QXtXCjZ1UrUYoy7LLtqvt72673axZszBz5kzH84KCAsTExDS0uV5l1GkxoGNrDOjYWu2mEBERXTNUCzdhYWHQarUuVZrc3FyX6oxdVFSU2/11Oh1at3YfAIxGI4xGozKNJiIioiZPtbqRwWBAYmIi0tPTnbanp6dj4MCBbo9JTk522X/z5s1ISkpyO96GiIiImh9VO8VmzpyJf/zjH/jggw9w9OhRPP7448jMzERqaioA0aU0fvx4x/6pqak4c+YMZs6ciaNHj+KDDz7A+++/jyeffFKtj0BERERNjKpjbsaMGYOLFy9i/vz5yM7ORo8ePbBx40a0b98eAJCdne205k1cXBw2btyIxx9/HG+//TbatGmDN998E/fff79aH4GIiIiaGFXXuVHDtbDODRERETmrz/e36rdfICIiIlISww0RERH5FIYbIiIi8ikMN0RERORTGG6IiIjIpzDcEBERkU9huCEiIiKfwnBDREREPoXhhoiIiHyKqrdfUIN9QeaCggKVW0JERER1Zf/ersuNFZpduCksLAQAxMTEqNwSIiIiqq/CwkKEhITUuk+zu7eUzWZDVlYWgoKCIEmSoucuKChATEwMzp49y/tWeRCvs/fwWnsHr7N38Dp7jyeutSzLKCwsRJs2baDR1D6qptlVbjQaDdq1a+fR9wgODub/OF7A6+w9vNbewevsHbzO3qP0tb5axcaOA4qJiIjIpzDcEBERkU9huFGQ0WjEnDlzYDQa1W6KT+N19h5ea+/gdfYOXmfvUftaN7sBxUREROTbWLkhIiIin8JwQ0RERD6F4YaIiIh8CsMNERER+RSGG4UsXboUcXFx8PPzQ2JiInbs2KF2k6453333He6++260adMGkiThyy+/dHpdlmXMnTsXbdq0gb+/P2655Rb8/PPPTvuYTCbMmDEDYWFhCAwMxD333IPff//di5+iaVuwYAGuv/56BAUFISIiAiNHjsTx48ed9uF1VsayZcvQq1cvxyJmycnJ+Oqrrxyv8zp7xoIFCyBJEtLS0hzbeK2VMXfuXEiS5PSIiopyvN6krrNMjbZ69WpZr9fL7733nnzkyBH5sccekwMDA+UzZ86o3bRrysaNG+XZs2fL69atkwHIX3zxhdPrCxculIOCguR169bJhw4dkseMGSNHR0fLBQUFjn1SU1Pltm3byunp6fK+ffvkW2+9Ve7du7dcXl7u5U/TNA0bNkxesWKFfPjwYTkjI0O+88475djYWLmoqMixD6+zMtavXy9v2LBBPn78uHz8+HH52WeflfV6vXz48GFZlnmdPWH37t1yhw4d5F69esmPPfaYYzuvtTLmzJkjJyQkyNnZ2Y5Hbm6u4/WmdJ0ZbhTQv39/OTU11WlbfHy8/Mwzz6jUomtf9XBjs9nkqKgoeeHChY5tZWVlckhIiPzOO+/IsizLV65ckfV6vbx69WrHPufOnZM1Go28adMmr7X9WpKbmysDkLdv3y7LMq+zp4WGhsr/+Mc/eJ09oLCwUO7cubOcnp4u33zzzY5ww2utnDlz5si9e/d2+1pTu87slmoks9mMvXv3IiUlxWl7SkoKdu3apVKrfM+pU6eQk5PjdJ2NRiNuvvlmx3Xeu3cvLBaL0z5t2rRBjx49+N+iBvn5+QCAVq1aAeB19hSr1YrVq1ejuLgYycnJvM4eMG3aNNx5550YOnSo03Zea2WdOHECbdq0QVxcHP74xz/it99+A9D0rnOzu3Gm0vLy8mC1WhEZGem0PTIyEjk5OSq1yvfYr6W763zmzBnHPgaDAaGhoS778L+FK1mWMXPmTNx4443o0aMHAF5npR06dAjJyckoKytDixYt8MUXX6B79+6Ov8h5nZWxevVq7Nu3D3v27HF5jb/TyhkwYABWrVqFLl264Pz583jppZcwcOBA/Pzzz03uOjPcKESSJKfnsiy7bKPGa8h15n8L96ZPn46DBw/i+++/d3mN11kZXbt2RUZGBq5cuYJ169ZhwoQJ2L59u+N1XufGO3v2LB577DFs3rwZfn5+Ne7Ha914I0aMcPzcs2dPJCcn47rrrsOHH36IG264AUDTuc7slmqksLAwaLVal9SZm5vrkmCp4ewj8mu7zlFRUTCbzbh8+XKN+5AwY8YMrF+/Hlu3bkW7du0c23mdlWUwGNCpUyckJSVhwYIF6N27N/7+97/zOito7969yM3NRWJiInQ6HXQ6HbZv344333wTOp3Oca14rZUXGBiInj174sSJE03ud5rhppEMBgMSExORnp7utD09PR0DBw5UqVW+Jy4uDlFRUU7X2Ww2Y/v27Y7rnJiYCL1e77RPdnY2Dh8+zP8WFWRZxvTp0/H555/j22+/RVxcnNPrvM6eJcsyTCYTr7OChgwZgkOHDiEjI8PxSEpKwtixY5GRkYGOHTvyWnuIyWTC0aNHER0d3fR+pxUdntxM2aeCv//++/KRI0fktLQ0OTAwUD59+rTaTbumFBYWyvv375f3798vA5AXL14s79+/3zGlfuHChXJISIj8+eefy4cOHZIfeOABt9MM27VrJ2/ZskXet2+ffNttt3E6ZxWPPvqoHBISIm/bts1pOmdJSYljH15nZcyaNUv+7rvv5FOnTskHDx6Un332WVmj0cibN2+WZZnX2ZOqzpaSZV5rpTzxxBPytm3b5N9++03+8ccf5bvuuksOCgpyfNc1pevMcKOQt99+W27fvr1sMBjkfv36OabWUt1t3bpVBuDymDBhgizLYqrhnDlz5KioKNloNMo33XSTfOjQIadzlJaWytOnT5dbtWol+/v7y3fddZecmZmpwqdpmtxdXwDyihUrHPvwOitj0qRJjr8TwsPD5SFDhjiCjSzzOntS9XDDa60M+7o1er1ebtOmjTxq1Cj5559/drzelK6zJMuyrGwtiIiIiEg9HHNDREREPoXhhoiIiHwKww0RERH5FIYbIiIi8ikMN0RERORTGG6IiIjIpzDcEBERkU9huCEiIiKfwnBDRM2SJEn48ssv1W4GEXkAww0Red3EiRMhSZLLY/jw4Wo3jYh8gE7tBhBR8zR8+HCsWLHCaZvRaFSpNUTkS1i5ISJVGI1GREVFOT1CQ0MBiC6jZcuWYcSIEfD390dcXBzWrl3rdPyhQ4dw2223wd/fH61bt8YjjzyCoqIip30++OADJCQkwGg0Ijo6GtOnT3d6PS8vD/fddx8CAgLQuXNnrF+/3vHa5cuXMXbsWISHh8Pf3x+dO3d2CWNE1DQx3BBRk/T888/j/vvvx4EDB/DQQw/hgQcewNGjRwEAJSUlGD58OEJDQ7Fnzx6sXbsWW7ZscQovy5Ytw7Rp0/DII4/g0KFDWL9+PTp16uT0HvPmzcPo0aNx8OBB3HHHHRg7diwuXbrkeP8jR47gq6++wtGjR7Fs2TKEhYV57wIQUcMpfp9xIqKrmDBhgqzVauXAwECnx/z582VZlmUAcmpqqtMxAwYMkB999FFZlmV5+fLlcmhoqFxUVOR4fcOGDbJGo5FzcnJkWZblNm3ayLNnz66xDQDk5557zvG8qKhIliRJ/uqrr2RZluW7775bfvjhh5X5wETkVRxzQ0SquPXWW7Fs2TKnba1atXL8nJyc7PRacnIyMjIyAABHjx5F7969ERgY6Hh90KBBsNlsOH78OCRJQlZWFoYMGVJrG3r16uX4OTAwEEFBQcjNzQUAPProo7j//vuxb98+pKSkYOTIkRg4cGCDPisReRfDDRGpIjAw0KWb6GokSQIAyLLs+NndPv7+/nU6n16vdznWZrMBAEaMGIEzZ85gw4YN2LJlC4YMGYJp06bh9ddfr1ebicj7OOaGiJqkH3/80eV5fHw8AKB79+7IyMhAcXGx4/WdO3dCo9GgS5cuCAoKQocOHfDNN980qg3h4eGYOHEiPv74YyxZsgTLly9v1PmIyDtYuSEiVZhMJuTk5Dht0+l0jkG7a9euRVJSEm688UZ88skn2L17N95//30AwNixYzFnzhxMmDABc+fOxYULFzBjxgyMGzcOkZGRAIC5c+ciNTUVERERGDFiBAoLC7Fz507MmDGjTu174YUXkJiYiISEBJhMJvz3v/9Ft27dFLwCROQpDDdEpIpNmzYhOjraaVvXrl1x7NgxAGIm0+rVqzF16lRERUXhk08+Qffu3QEAAQEB+Prrr/HYY4/h+uuvR0BAAO6//34sXrzYca4JEyagrKwMb7zxBp588kmEhYXhD3/4Q53bZzAYMGvWLJw+fRr+/v4YPHgwVq9ercAnJyJPk2RZltVuBBFRVZIk4YsvvsDIkSPVbgoRXYM45oaIiIh8CsMNERER+RSOuSGiJoe95UTUGKzcEBERkU9huCEiIiKfwnBDREREPoXhhoiIiHwKww0RERH5FIYbIiIi8ikMN0RERORTGG6IiIjIp/x/m081Ssd/shoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Predictions: [0 1 1 0 0]\n",
      "Actual Labels: [0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Make Predictions\n",
    "loaded_model = tf.keras.models.load_model(\"/mnt/data/tic-tac-toe.keras\")  # Load correctly\n",
    "sample_X = X_test[:5]  # Select 5 random samples from test set\n",
    "predictions = loaded_model.predict(sample_X)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Predictions:\", predicted_classes)\n",
    "print(\"Actual Labels:\", y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improve Your Model\n",
    "\n",
    "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
    "\n",
    "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
    "\n",
    "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
    "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
    "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
    "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach(es) did you find helpful to improve your model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
